DOI,Title,Publication Date,Description,Creators,Type,License,URL
10.5281/zenodo.11396622,Instruks Dataset - A dataset of Clinical Guidelines in Denmark,2024-05-30,"Dataset of Clinical Guidelines used by Danish municipalities, collected in 2023 under permission of Region Syddanmark, Midtjylland, Nordjylland, Sj&aelig;lland and Hovedstaden. &nbsp; The zip file ClinicalGuidelines.raw contains the following folders: <ul> <li> HTML_RegionHovedstaden: Clinical Guidelines used in the capital region (Hovedstaden) </li> <li> HTML_RegionMidt: Clinical Guidelines used in the region of Midtjylland, </li> <li> HTML_RegionNord: Clinical Guidelines used in the region of Nordjylland </li> <li> HTML_RegionSj&aelig;lland: Clinical Guidelines used in the region of Sj&aelig;lland, </li> <li> HTML_RegionSyd: Clinical Guidelines used in the Syddanmark region. The dataset has been collected with the consent of each of the areas. The dataset contains HTML files (that have been sanitized in follow-up versions of the datasets). &nbsp; </li> </ul> The dataset is the accompanying material for the paper ""Automating Pathway Extraction from Clinical Guidelines: A Conceptual Model, Datasets and Initial Experiments"" by Daniel Grathwol, Han van der Aa, and Hugo A. L&oacute;pez. To appear in the 30th International Conference on Cooperative Information Systems.&nbsp;","Daniel, Grathwol, van der Aa, Han, López, Hugo-Andrés",dataset,cc-by-nc-4.0,https://zenodo.org/records/11396622
10.5281/zenodo.15516432,"Digital game-based Learning in den Bereichen Wirtschaft, Finanzen und Nachhaltigkeit",2025-05-26,"In der neunten Veranstaltung der Ringvorlesung &bdquo;Around the W&Ouml;RLD&ldquo; im Rahmen des vom BMBF gef&ouml;rderten Projekts &bdquo;W&Ouml;RLD &ndash; Wirtschaftsp&auml;dagogik und &Ouml;konomische Bildung: Lehrkr&auml;ftebildung und Unterricht digital&ldquo; gibt Jasmin Vanessa Engelhardt von der Universit&auml;t Mannheim Einblick in den unterrichtlichen Einsatz von Serious Games in den Bereichen Wirtschaft, Finanzen und Nachhaltigkeit sowie in ein entwickeltes Schema zur Evaluation von Serious Games. Im Anschluss erhielten die Teilnehmenden die Gelegenheit, dieses Evaluationsschema an konkreten Games der drei Bereiche auszuprobieren und dar&uuml;ber in den Austausch zu kommen. Weitere Informationen finden Sie unter: https://www.uni-mannheim.de/mife/forschung/dgbl-wifina-digital-game-based-learning/","Aprea, Carmela, Suna, Merve, Engelhardt, Jasmin Vanessa",video,cc-by-sa-4.0,https://zenodo.org/records/15516432
10.5281/zenodo.11234583,RUEG Corpus,2024-04-30,"The Research Unit Emerging Grammars (RUEG) investigates the linguistic systems and linguistic resources of bilingual speakers from families with an immigrant history, &ldquo;heritage speakers&rdquo;, in both of their languages across different language pairs, registers, and age groups. We investigate speakers of Russian, Turkish, and Greek as heritage languages in Germany and the U.S., in addition to German as a heritage language in the U.S., as well as monolingual controls for majority and heritage languages. We study noncanonical phenomena as indicators of new grammatical options in bilingual systems. All projects contribute to<br>three &ldquo;Joint Ventures&rdquo; targeting (1) the development of new dialects vs. incomplete acquisition or erosion (&ldquo;Language Change Hypothesis&rdquo;), (2) the relevance of internal vs. external grammatical interfaces (&ldquo;Interface Hypothesis&rdquo;), and (3) the distinction of contact-induced change vs. language-internal developments and variation (&ldquo;Internal Dynamics Hypothesis&rdquo;). As a result of our collaborative research, we expect new insights into the special dynamics of language variation, language change and linguistic repertoires in contact situations and the modelling of noncanonical structures in the grammatical system, and new impulses for the investigation of heritage speakers and of speakers&rsquo; resources. The projects are supported by two Mercator Fellows: <a href=""http://www.sociolinguistics.uottawa.ca/shanapoplack/"">Shana Poplack, University of Ottawa</a> <a href=""http://ling.umd.edu/people/person/maria-polinsky/"">Maria Polinsky, University of Maryland</a> <a href=""https://www.reading.ac.uk/elal/staff/professor-jeanine-treffers-daller"" target=""_blank"" rel=""noopener"">Jeanine Treffers-Daller, University of Reading</a> <a href=""http://cehum.ilch.uminho.pt/researchers/2"">Cristina Flores, Universidade do Minho</a> The Research Unit is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) &ndash; Project numbers: 39482131 &amp; 313607803. You can search this data online in ANNIS: <a href=""https://korpling.german.hu-berlin.de/annis/"">https://korpling.german.hu-berlin.de/annis/</a>","Lüdeling, Anke, Alexiadou, Artemis, Allen, Shanley, Bunk, Oliver, Gagarina, Natalia, Grigoriadou, Sofia, Hartz, Rahel Gajaneh, Iefremenko, Kateryna, Jahns, Esther, Katsika, Kalliopi, Keller, Mareike, Klotz, Martin, Krause, Thomas, Labrenz, Annika, Martynova, Maria, Özsoy, Onur, Pashkova, Tatiana, Pohle, Maria, Purkarthofer, Judith, Rizou, Vicky, Schroeder, Christoph, Shadrova, Anna, Szucsich, Luka, Tracy, Rosemarie, Tsehaye, Wintai, Wiese, Heike, Zerbian, Sabine, Zuban, Yulia, Zürn, Nadine",dataset,cc-zero,https://zenodo.org/records/11234583
10.5281/zenodo.10144428,UB-Mannheim/reichsanzeiger-gt: 1.0.0,2023-11-15,<h2>What's Changed</h2> <ul> <li>replace double whitespaces by single one by @shigapov in https://github.com/UB-Mannheim/reichsanzeiger-gt/pull/2</li> </ul> <h2>New Contributors</h2> <ul> <li>@shigapov made their first contribution in https://github.com/UB-Mannheim/reichsanzeiger-gt/pull/2</li> </ul> <strong>Full Changelog</strong>: https://github.com/UB-Mannheim/reichsanzeiger-gt/commits/1.0.0,"Schmidt, Thomas, Kamlah, Jan, Weil, Stefan, Shigapov, Renat",software,cc-by-4.0,https://zenodo.org/records/10144428
10.5281/zenodo.13919,The SOPRAN Aeolotron November 2014 Seawater Gas Exchange Experiment,2014-12-18,"The video reports on the first air-sea gas exchange measurements with seawater from the Atlantic Ocean in the Aeolotron, including the effects of the natural surface micro layer and bubbles. In addition, aerosols were sampled with different techniques to investigate to what extent organic material from the sea surface micro layer (SML) is carried into aerosol. The experiments will also be essential for the provide further experimental data for the new SOPRAN air-sea gas transfer model with conditions, where data are not yet available. The project is funded within the SOPRAN project by the BMBF as the German part of the SOLAS initiative.  The participating groups were J. Williams, MPI for Chemistry, Mainz (PTR-MS measurements of gas concentrations in air and water), A. Engel, GEOMAR Helmholtz Centre for Ocean Research Kiel (SML measurements), M. van Pinxteren, TROPOS (aerosol measurements), and B. J&auml;hne, U. Heidelberg (MIMS and FTIR gas exchange measurements, active and passive thermography, and all environmental parameters including wave slope imaging). External groups include O. Wurl, ICBM (CO2 gas exchange and SML measurements), B. Schneider, IOW (CO2 measurements), and foreign groups from England (J. Najera, U. Manchester) and France (B. D&#39;Anna, CNRS, lab IRCELYON). The latter two groups supported the aerosol measurements.&nbsp; The experiment took place in November 2014. On September 23, twenty tonnes of Atlantic seawater, sampled from the Northern Atlantic Ocean on board of the research vessel POSEIDON and reloaded to a road tanker at GEOMAR, arrived in Heidelberg and were filled into the storage tanks in the basement of the building, where the Aeolotron is located.",Campus TV,video,cc-by-4.0,https://zenodo.org/records/13919
10.5281/zenodo.3946462,TaxGraph - A Knowledge Graph of Multi-National Companies and their Relationships,2020-07-15,"The taxation of multi-national companies is a complex field, since it is influenced by the legislation of several states. Laws in different states may have unforeseen interaction effects, which can be exploited by allowing multi-national companies to minimize and avoid taxes.  Thus, we created a knowledge graph of multi-national companies and their relationships. Many commonly known tax avoidance strategies can be formulated as subgraph queries to this graph, which allows for identifying companies using certain strategies. Moreover, we can identify anomalies in the graph which hint at potential tax avoidance strategies.","Lüdemann, Niklas, Shiba, Ageda, Thymianis, Nikolaos, Heist, Nicolas, Ludwig, Christopher, Paulheim, Heiko",dataset,cc-by-4.0,https://zenodo.org/records/3946462
10.5281/zenodo.1320150,KGloVe DBpedia predicate frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a predicate frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.<br> &nbsp;","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320150
10.5281/zenodo.1320154,KGloVe DBpedia predicate object frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a predicate object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320154
10.5281/zenodo.1320810,RDF2Vec DBpedia inverse Page Rank frequency embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a inverse Page Rank frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320810
10.5281/zenodo.1320081,RDF2Vec DBpedia predicate frequency embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a predicate frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320081
10.5281/zenodo.1320211,RDF2Vec DBpedia predicate object frequency embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a predicate object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320211
10.5281/zenodo.1320148,KGloVe DBpedia uniform embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a uniformly weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320148
10.5281/zenodo.8422037,SOTAB V2 for SemTab 2023,2023-10-09,"SOTAB V2 for SemTab 2023 includes datasets used to evaluate <a href=""https://paperswithcode.com/task/column-type-annotation"">Column Type Annotation </a>(CTA)&nbsp;and <a href=""https://paperswithcode.com/task/columns-property-annotation"">Columns Property Annotation</a> (CPA)&nbsp;systems in the 2023 edition of the <a href=""https://www.cs.ox.ac.uk/isg/challenges/sem-tab/"">SemTab challenge</a>. The datasets for both rounds of the challenge were down-sampled from the full train, test and validation splits of the&nbsp;<a href=""http://webdatacommons.org/structureddata/sotab/v2/"">SOTAB V2</a> (WDC Schema.org Table Annotation Benchmark version 2) benchmark, so that the datasets of the first round have a smaller vocabulary&nbsp;of 40 and 50 labels for CTA and CPA respectively corresponding to easier/more general domains, and the datasets of the second round include the full vocabulary size of 80 and 105 labels and are therefore considered to be harder to annotate. The columns and the relationships between columns are annotated using the Schema.org and DBpedia vocabulary.  SOTAB V2 for SemTab 2023&nbsp;contains the splits used in Round 1 and Round 2 of the challenge. Each round includes a training, validation and test split together with the ground truth for the test splits and the vocabulary list. The ground truth of the test sets of both rounds are manually verified.  Files contained in&nbsp;SOTAB V2 for SemTab 2023:  <ol> 	<li>Round1-SOTAB-CPA-DatasetsAndGroundTruth = This file contains the csv files of the first round of the challenge for the task of CPA for&nbsp;training, validation and test set,&nbsp; as well as label set and ground truth in the &quot;gt&quot; folder. The columns in these files are annotated with Schema.org.</li> 	<li>Round1-SOTAB-CTA-DatasetsAndGroundTruth = This file contains the csv files of the first round of the challenge for the task of CTA for&nbsp;training, validation and test set,&nbsp; as well as label set and ground truth in the &quot;gt&quot; folder. The columns in these files are annotated with Schema.org.</li> 	<li>Round2-SOTAB-CPA-SCH-DatasetsAndGroundTruth = This file contains the csv files of the second round of the challenge for the task of CPA for&nbsp;training, validation and test set,&nbsp; as well as label set and ground truth in the &quot;gt&quot; folder. The columns in these files are annotated with Schema.org.</li> 	<li>Round2-SOTAB-CTA-SCH-DatasetsAndGroundTruth = This file contains the csv files of the second round of the challenge for the task of CTA for&nbsp;training, validation and test set,&nbsp; as well as label set and ground truth in the &quot;gt&quot; folder. The columns in these files are annotated with Schema.org.</li> 	<li>Round2-SOTAB-CPA-DBP-DatasetsAndGroundTruth = This file contains the csv files of the second round of the challenge for the task of CPA for&nbsp;training, validation and test set,&nbsp; as well as label set and ground truth in the &quot;gt&quot; folder. The columns in these files are annotated with DBpedia.</li> 	<li>Round2-SOTAB-CTA-DBP-DatasetsAndGroundTruth = This file contains the csv files of the second round of the challenge for the task of CTA for&nbsp;training, validation and test set,&nbsp; as well as label set and ground truth in the &quot;gt&quot; folder. The columns in these files are annotated with DBpedia.</li> </ol>  All the corresponding tables can be found in the &quot;Tables&quot; zip folders.  &nbsp;  Note on License: This data includes data from the following sources. Refer to each source for license details:  - CommonCrawl&nbsp;<a href=""https://commoncrawl.org/"">https://commoncrawl.org/</a>  THIS DATA IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","Korini, Keti, Peeters, Ralph, Bizer, Christian",dataset,cc-by-4.0,https://zenodo.org/records/8422037
10.5281/zenodo.1320032,KGloVe DBpedia inverse Page Rank split embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a inverse Page Rank split&nbsp;weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320032
10.5281/zenodo.1320159,KGloVe DBpedia inverse predicate object frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a inverse predicate object frequency&nbsp;weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320159
10.5281/zenodo.1318146,RDF2Vec DBpedia uniform embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a uniformly weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In <em>Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics</em> (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1318146
10.5281/zenodo.1320165,KGloVe DBpedia object frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320165
10.5281/zenodo.1320030,KGloVe DBpedia inverse Page Rank embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a inverse Page Rank weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320030
10.5281/zenodo.1320042,RDF2Vec DBpedia Page Rank split embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a Page Rank split weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320042
10.5281/zenodo.3482775,Uncovering the Semantics of Wikipedia Categories - Axioms and Assertions,2019-10-11,"Resulting axioms and assertions from applying the Cat2Ax approach to the DBpedia knowledge graph.<br> The methodology is described in the conference publication &quot;N. Heist, H. Paulheim: Uncovering the Semantics of Wikipedia Categories, International Semantic Web Conference, 2019&quot;.","Heist, Nicolas, Paulheim, Heiko",dataset,mit-license,https://zenodo.org/records/3482775
10.5281/zenodo.1320001,RDF2Vec DBpedia inverse object frequency embeddings,2017-06-19,"This dataset contains the vectors from computing rdf2vec embeddings from a inverse object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320001
10.5281/zenodo.1320005,RDF2Vec DBpedia inverse page rank split embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a inverse page rank split weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320005
10.5281/zenodo.1320013,RDF2Vec DBpedia inverse predicate object frequency embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a inverse predicate object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320013
10.5281/zenodo.2017356,RDF2Vec DBpedia uniform embeddings in HDF5 file format,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a uniformly weighted DBpedia 2016-04 graph.  The file has a group called &quot;Vectors&quot; which contains a dataset for each entity in the graph. The dataset name is the entity name and the dataset content&nbsp;is the embedded vector&nbsp;(length 200).  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In <em>Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics</em> (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/2017356
10.5281/zenodo.1320038,RDF2Vec DBpedia Page Rank embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a Page Rank weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279<br> &nbsp;","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320038
10.5281/zenodo.1320028,KGloVe DBpedia inverse object split embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a inverse object split weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320028
10.5281/zenodo.1320015,RDF2Vec DBpedia object frequency embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320015
10.5281/zenodo.1320018,KGloVe DBpedia inverse object frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a inverse object frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In&nbsp;The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320018
10.5281/zenodo.1320007,RDF2Vec DBpedia inverse predicate frequency embeddings,2017-06-19,"This dataset contains the vectors from computing RDF2vec embeddings from a&nbsp;inverse predicate frequency&nbsp;weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Biased graph walks for RDF graph embeddings. In Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS &#39;17). ACM, New York, NY, USA, Article 21, 12 pages. DOI: https://doi.org/10.1145/3102254.3102279","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320007
10.5281/zenodo.1320167,KGloVe DBpedia Page Rank frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a Page Rank frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320167
10.5281/zenodo.1320152,KGloVe DBpedia inverse predicate frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a inverse predicate frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320152
10.5281/zenodo.1320169,KGloVe DBpedia Page Rank split frequency embeddings,2017-10-21,"This dataset contains the vectors from computing KGloVe embeddings from a Page Rank split frequency weighted DBpedia 2016-04 graph.  For each entity in the graph, the text file in the zip archive contains a line with the entity name and the embedded vector.  The parameter settings for the embedding are as specified in the paper:  Michael Cochez, Petar Ristoski, Simone Paolo Ponzetto, and Heiko Paulheim. 2017. Global RDF Vector Space Embeddings. In The Semantic Web &ndash; ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21&ndash;25, 2017, Proceedings, Part I.","Cochez, Michael, Ristoski, Petar, Ponzetto, Simone Paulo, Paulheim, Heiko",dataset,cc-by-sa-4.0,https://zenodo.org/records/1320169
10.5281/zenodo.6962676,Diversity-Driven Unit Test Generation (Data Set),2022-08-04,"The goal of automated unit test generation tools is to create a set of test cases for the software under test that achieve the highest possible coverage for the selected test quality criteria. The most&nbsp;effective approaches for achieving this goal at the present time use meta-heuristic optimization&nbsp;algorithms to search for new test cases using fitness functions defined on existing sets of test<br> cases and the system under test. Regardless of how their search algorithms are controlled, however, all existing approaches focus on the analysis of exactly one implementation, the software&nbsp;under test, to drive their search processes, which is a limitation on the information they have&nbsp;available. In this paper we investigate whether the practical effectiveness of white box unit test&nbsp;generation tools can be increased by giving them access to multiple, diverse implementations&nbsp;of the functionality under test harvested from widely available Open Source software repositories. After presenting a basic implementation of such an approach, DivGen (Diversity-driven&nbsp;Generation), on top of the leading test generation tool for Java (EvoSuite), we assess the performance of DivGen compared to EvoSuite when applied in its traditional, mono-implementation&nbsp;oriented mode (MonoGen). The results show that while DivGen outperforms MonoGen in 33%&nbsp;of the sampled classes for mutation coverage (+16% higher on average), MonoGen outperforms<br> DivGen in 12.4% of the classes for branch coverage (+10% higher average).","Kessel, Marcus, Atkinson, Colin",dataset,cc-by-4.0,https://zenodo.org/records/6962676
10.5281/zenodo.6509715,DLCC Gold Standard,2022-05-01,"Corresponding GitHub repository: <a href=""https://github.com/janothan/DL-TC-Generator"">DL-TC-Generator on GitHub</a>  &nbsp;  <strong>Abstract</strong>  Knowledge graph embedding is a representation learning technique which projects entities and relations in a knowledge graph to continuous vector spaces.<br> Embeddings have gained a lot of uptake and have been heavily used in link prediction and other downstream prediction tasks.<br> Most approaches are evaluated on a single task or a single group of tasks to determine their overall performance. The evaluation is then assessed in terms of how well the embedding approach performs on the task at hand, but it is hardly evaluated (and often not even deeply understood) what information the embedding approaches are <em>actually</em> learning to represent.  To fill this gap, we present the DLCC (Description Logic Class Constructors) benchmark, a resource to analyze embedding approaches in terms of which kinds of classes they can represent. Two gold standards are presented, one based on the real world knowledge graph DBpedia, and one synthetic gold standard.","Portisch, Jan, Paulheim, Heiko",dataset,cc-by-4.0,https://zenodo.org/records/6509715
10.5281/zenodo.7777506,"Dataset for Manually Coded Firm Founding Dates, CEO Duality, and CEO Photograph Prominence in Annual Reports",2021-06-01,"In this dataset, we wish to make available some measures which we manually coded as part of our PhDs.&nbsp;It contains manually coded information on S&amp;P1500 firms and their CEOs, specifically, the firm&rsquo;s founding year, whether the CEO is simultaneously chairperson of the board (CEO duality), and the prominence of the CEO in photographs in the firm&rsquo;s annual report. More information can be found in the attached documentation. Both authors contributed equally to the creation of this dataset.  Since this is the first version of this dataset, we are happy about any feedback, corrections, or additions. Please reach out to us in case you spot any irregularities or have questions via mappels@mail.uni-mannheim.de or&nbsp;mkowalzi@staff.mail.uni-mannheim.de.&nbsp;  &nbsp;  The creation of this dataset was supported by the <a href=""https://de.wikiversity.org/wiki/Wikiversity:Fellow-Programm_Freies_Wissen"">Fellowship Freies Wissen</a> of the Wikimedia Foundation. More information on the project can be found <a href=""https://de.wikiversity.org/wiki/Wikiversity:Fellow-Programm_Freies_Wissen/Einreichungen/Lowering_the_Barriers_for_Young_Strategy_Scholars:_An_Open-Access_Database_for_Manually_Computed_Variables_of_Strategy_Research"">here</a>.","Moritz Appels, Marc Kowalzick",dataset,cc-by-4.0,https://zenodo.org/records/7777506
10.5281/zenodo.3479126,Uncovering the Semantics of Wikipedia Categories - Code,2019-10-10,A tool to uncover the semantics of Wikipedia categories by learning relation and type axioms to enrich the ontology of a Wikipedia-based knowledge graph,"Heist, Nicolas, Paulheim, Heiko",software,mit-license,https://zenodo.org/records/3479126
10.5281/zenodo.8208246,Data Set: Promoting Open Science in Test-Driven Software Experiments,2023-08-02,Data set for reproduction purposes (tabular data is stored using Apache&#39;s Parqet format).,"Marcus Kessel, Colin Atkinson",dataset,cc-by-4.0,https://zenodo.org/records/8208246
10.5281/zenodo.7817022,Gollum: A Gold Standard for Large Scale\\Multi Source Knowledge Graph Matching,2022-05-06,"The set of Knowledge Graphs (KGs) generated with automatic and manual approaches is constantly growing.<br> For an integrated view and usage, an alignment between these KGs is necessary on the schema as well as instance level.<br> There are already approaches which try to tackle this multi source knowledge graph matching problem,<br> but large gold standards are missing to evaluate their effectiveness and scalability.<br> In particular, most existing gold standards are fairly small and can be solved by matchers which match exactly two KGs (1:1), which are the majority of existing matching systems.<br> <br> We close this gap by presenting Gollum&nbsp;-- a gold standard for large-scale multi source knowledge graph matching with over 275,000 correspondences between 4,149 different KGs.<br> They originate from knowledge graphs derived by applying the DBpedia extraction framework to a large wiki farm.<br> <br> Three variations of the gold standard are made available:<br> (1) a version with all correspondences for evaluating unsupervised matching approaches, and two versions for evaluating supervised matching: (2) one where each KG is contained both in the train and test set, and (3) one where each KG is exclusively contained in the train or the test set.  <br> We plan to extend our KG track at the Ontology Alignment Evaluation Initiative (OAEI) to allow for matching systems&nbsp;<br> which are specifically designed to solve the multi KG matching problem.<br> As a first step towards this direction, we evaluate multi source matching approaches which reuse two-KG (1:1) matchers from the past OAEI.  &nbsp;  Due to the size of the KG files, they are hosted at the institute:  <a href=""http://data.dws.informatik.uni-mannheim.de/dbkwik/gollum/40K.tar"">http://data.dws.informatik.uni-mannheim.de/dbkwik/gollum/40K.tar</a>&nbsp; &nbsp; (50,3 GB)<br> <a href=""http://data.dws.informatik.uni-mannheim.de/dbkwik/gollum/all.tar"">http://data.dws.informatik.uni-mannheim.de/dbkwik/gollum/all.tar</a>&nbsp; &nbsp; &nbsp; (74,7 GB)<br> <a href=""http://data.dws.informatik.uni-mannheim.de/dbkwik/gollum/gold.tar"">http://data.dws.informatik.uni-mannheim.de/dbkwik/gollum/gold.tar</a>&nbsp; &nbsp;(25,3 GB)","Herting,Sven, Paulheim,Heiko",dataset,cc-by-3.0,https://zenodo.org/records/7817022
10.5281/zenodo.8068322,CaLiGraph - A Large-Scale Semantic Knowledge Graph compiled from Wikipedia Categories and List Pages,2023-06-22,"CaLiGraph is a large-scale semantic knowledge graph with a rich ontology which is compiled from the DBpedia ontology, and Wikipedia categories &amp; list pages. For more information, visit http://caligraph.org  Information about uploaded files:<br> (all files are b-zipped and in the n-triple format)<br> <br> <strong>caligraph-metadata.nt.bz2</strong><br> Metadata about the dataset which is described using void vocabulary.  <strong>caligraph-ontology.nt.bz2</strong><br> Class definitions, property definitions, restrictions,&nbsp;and labels of the CaLiGraph ontology.  <strong>caligraph-ontology_dbpedia-mapping.nt.bz2</strong><br> Mapping of classes and properties to the DBpedia ontology.  <strong>caligraph-ontology_provenance.nt.bz2</strong><br> Provenance information about classes (i.e. which Wikipedia category or list page has been used to create this class).  <strong>caligraph-instances_types.nt.bz2</strong><br> Definition of instances and (non-transitive) types.  <strong>caligraph-instances_transitive-types.nt.bz2</strong><br> Transitive types for instances (can also be induced by a reasoner).  <strong>caligraph-instances_labels.nt.bz2</strong><br> Labels for instances.  <strong>caligraph-instances_relations.nt.bz2</strong><br> Relations between instances derived from the class restrictions of the ontology (can also be induced by a reasoner).  <strong>caligraph-instances_dbpedia-mapping.nt.bz2</strong><br> Mapping of instances to respective DBpedia instances.  <strong>caligraph-instances_provenance.nt.bz2</strong><br> Provenance information about instances (e.g.&nbsp;if the instance has been extracted from a Wikipedia list page).  <strong>dbpedia_caligraph-instances.nt.bz2</strong><br> Additional instances of CaLiGraph that are not in DBpedia.<br> ! This file is no part of CaLiGraph but should rather be used as an extension to DBpedia. The triples use the DBpedia namespace and&nbsp;can thus be used to directly extend DBpedia.&nbsp;!  <strong>dbpedia_caligraph-types.nt.bz2</strong><br> Additional types of CaLiGraph that are not in DBpedia.<br> ! This file is no part of CaLiGraph but should rather be used as an extension to DBpedia. The triples use the DBpedia namespace and&nbsp;can thus be used to directly extend DBpedia.&nbsp;!  <strong>dbpedia_caligraph-relations.nt.bz2</strong><br> Additional relations of CaLiGraph that are not in DBpedia.<br> ! This file is no part of CaLiGraph but should rather be used as an extension to DBpedia. The triples use the DBpedia namespace and&nbsp;can thus be used to directly extend DBpedia.&nbsp;!  &nbsp;  <strong>Changelog</strong>  v3.1.1  <ul> 	<li>Fixed an encoding issue in caligraph-ontology.nt.bz2</li> </ul>  v3.1.0  <ul> 	<li>Fixed several issues related to ontology consistency and structure</li> </ul>  v3.0.0  <ul> 	<li>Added functionality to group mentions of unknown entities into distinct entities</li> </ul>  v2.1.0  <ul> 	<li>Fixed error that lead to a class inheriting from a disjoint class</li> 	<li>Introduced owl:ObjectProperty&nbsp;and owl:DataProperty&nbsp;instead of rdf:Property</li> 	<li>Several cosmetic fixes</li> </ul>  v2.0.2  <ul> 	<li>Fixed incorrect formatting of some properties</li> </ul>  v2.0.1  <ul> 	<li>Better entity extraction and representation</li> 	<li>Small cosmetic fixes</li> </ul>  v2.0.0  <ul> 	<li>Entity extraction from arbitrary tables and enumerations in Wikipedia pages</li> </ul>  v1.4.0  <ul> 	<li>BERT-based recognition of subject entities and improved language models from spaCy 3.0</li> </ul>  v1.3.1  <ul> 	<li>Fixed minor encoding errors and improved formatting</li> </ul>  v1.3.0  <ul> 	<li>CaLiGraph is now based on a recent version of Wikipedia and DBpedia from November 2020</li> </ul>  v1.1.0  <ul> 	<li>Improved the CaLiGraph type hierarchy</li> 	<li>Many small bugfixes and improvements</li> </ul>  v1.0.9  <ul> 	<li>Additional alternative labels for CaLiGraph instances</li> </ul>  v1.0.8  <ul> 	<li>Small cosmetic changes to URIs to be closer to DBpedia URIs</li> </ul>  v1.0.7  <ul> 	<li>Mappings from CaLiGraph classes to DBpedia classes are now realised via rdfs:subClassOf instead of owl:equivalentClass</li> 	<li>Entities are now URL-encoded to improve accessibility</li> </ul>  v1.0.6  <ul> 	<li>Fixed a bug in the ontology creation step that led to a substantially lower amount of sub-type relationships than actually exist. The new version provides a richer type hierarchy that also leads to an increased amount of types for resources.</li> </ul>  v1.0.5  <ul> 	<li>Fixed a bug that has declared CaLiGraph predicates as subclasses of owl:Predicate instead of being of the type owl:Predicate.</li> </ul>","Heist, Nicolas, Paulheim, Heiko",dataset,cc-by-4.0,https://zenodo.org/records/8068322
10.5281/zenodo.1174041,Improving Hypernymy Extraction with Distributional Semantic Classes,2018-02-16,"In this paper, we show for the first time how distributionally-induced semantic classes can be helpful for extraction of hypernyms. We &nbsp;present a method for (1) inducing sense-aware semantic classes using distributional semantics and (2) using these induced semantic classes for filtering noisy hypernymy relations. Denoising of hypernyms is performed by labeling each semantic class with its hypernyms. On one hand, this allows us to filter out wrong extractions using the global structure of the distributionally similar senses. On the other hand, we infer missing hypernyms via label propagation to cluster terms. We conduct a large-scale crowdsourcing study showing that processing of automatically extracted hypernyms using our approach improves the quality of the hypernymy extraction both in terms of precision and recall. Furthermore, we show the utility of our method in the domain taxonomy induction task, achieving the state-of-the-art results on a benchmarking dataset.  This particular page contains datasets related to the paper. Namely the input induced word senses, a database of hypernyms, and the output clusters of senses labeled with hypernyms -- the distributional semantic classes. The semantic classes are of two granularities, as described in the paper (coarse and fine grained).&nbsp;","Alexander Panchenko, Dmitry Ustalov, Stefano Faralli, Simone P. Ponzetto, Chris Biemann",dataset,cc-by-sa-4.0,https://zenodo.org/records/1174041
10.5281/zenodo.6039372,GeNeG: German News Knowledge Graph,2022-02-10,"GeNeG is a knowledge graph constructed from news articles on the topic of refugees and migration, collected from German online media outlets. GeNeG contains rich textual and metadata information, as well as named entities extracted from the articles&#39; content and metadata and linked to Wikidata. The graph is expanded with up to three-hop neighbors from Wikidata of the initial set of linked entities.  GeNeG comes in three flavors:  <ul> 	<li>Base GeNeG: contains textual information, metadata, and linked entities extracted from the articles.</li> 	<li>Entities GeNeG: derived from the Base GeNeG by removing all literal nodes, it contains only resources and it is enriched with three-hop Wikidata neighbors of the entities extracted from the articles.</li> 	<li>Complete GeNeG: the combination of the Base and Entities GeNeG, it contains both literals and resources.</li> </ul>  Information about uploaded files:  (all files are b-zipped and in the N-Triples&nbsp;format.)  <table align=""left""> 	<thead> 		<tr> 			<th scope=""col""><strong>File</strong></th> 			<th scope=""col""><strong>Description</strong></th> 		</tr> 	</thead> 	<tbody> 		<tr> 			<td>geneg_<em>type</em>-metadata.nt.bz2</td> 			<td>Metadata about the dataset, described using void vocabulary.</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-instances_types.nt.bz2</td> 			<td>Class definitions of articles and events.</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-instances_labels.nt.bz2</td> 			<td>Labels of instances.</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-instances_metadata_literals.nt.bz2</td> 			<td>Relations between news article resurces and metadata literals (e.g. URL, publishing date, modification date, polarity score, stance).</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-instances_metadata_resources.nt.bz2</td> 			<td>Relations between news article resources and metadata entities (i.e. publishers, authors, keywords).</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-instances_content_relations.nt.bz2</td> 			<td>Relations between news article resources and content components (e.g. titles, abstracts, article bodies).</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-instances_event_mapping.nt.bz2</td> 			<td>Mapping of news article resources to events.</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-event_relations.nt.bz2</td> 			<td>Relations between news events and entities mentioned (i.e. actors, places, mentions).</td> 		</tr> 		<tr> 			<td>geneg_<em>type</em>-wiki_relations.nt.bz2</td> 			<td>Relations between news event Wikidata entities and their&nbsp;<em>k</em>-hop entities neighbors from Wikidata.</td> 		</tr> 	</tbody> </table>  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  <strong>Changelog</strong>  v1.0.1  <ul> 	<li>Stance annotations have been added to the Base and Complete GeNeG.</li> </ul>","Andreea Iana, Alexander Grote, Kaharina Ludwig, Mehwish Alam, Philipp Müller, Christof Weinhardt, Harald Sack, Heiko Paulheim",dataset,,https://zenodo.org/records/6039372
10.5281/zenodo.7908392,NeMig - A Bilingual News Collection and Knowledge Graph about Migration,2022-12-15,"NeMig represents a bilingual news collection and knowledge graphs on the topic of migration. The news corpora in German and English were collected from online media outlets from Germany and the US, respectively. NeMIg contains rich textual and metadata information, sentiment and political orientation annotations, as well as named entities extracted from the articles&#39; content and metadata and linked to Wikidata. The corresponding knowledge graphs (NeMigKG) built from each corpus are expanded with up to two-hop neighbors from Wikidata of the initial set of linked entities.  NeMigKG comes in four flavors, for both the German, and the English corpora:  <ul> 	<li>Base NeMigKG: contains literals and entities from the corresponding annotated news corpus;</li> 	<li>Entities NeMigKG: derived from the Base NeMIg by removing all literal nodes, it contains only resource nodes;</li> 	<li>Enriched Entities NeMigKG: derived from the Entities NeMig by enriching it with up to two-hop neighbors from Wikidata, it contains only resource nodes and Wikidata triples;</li> 	<li>Complete NeMigKG: the combination of the Base and Enriched Entities NeMig, it contains both literals and resources.</li> </ul>  Information about uploaded files:  (all files are b-zipped and in the N-Triples&nbsp;format.)  A description of the <strong>NeMigKG files</strong> is provided in the table below:  <table align=""left""> 	<caption>NeMigKG Files Description</caption> 	<thead> 		<tr> 			<th scope=""col"">File</th> 			<th scope=""col"">Description</th> 		</tr> 	</thead> 	<tbody> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-metadata.nt.bz2</td> 			<td>Metadata about the dataset, described using void vocabulary.</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_types.nt.bz2</td> 			<td>Class definitions of news and event instances.</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_labels.nt.bz2</td> 			<td>Labels of instances.</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_related.nt.bz2</td> 			<td>Relations between news instances based on one another.</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_metadata_literals.nt.bz2</td> 			<td>Relations between news instances and metadata literals (e.g. URL, publishing date, modification date, sentiment label, political orientation of news outlets).</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_content_mapping.nt.bz2</td> 			<td>Mapping of news instances to content instances (e.g. title, abstract, body).</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_topic_mapping.nt.bz2</td> 			<td>Mapping of news instances to sub-topic instances.</td> 		</tr> 		<tr> 			<td> 			nemig_<em>${language</em>}_ <em>$</em>{<em>graph_type</em>}-instances_sentiment_mapping.nt.bz2 			</td> 			<td> 			Mapping of news instances to sentiment classes. 			</td> 		</tr> 		<tr> 			<td> 			emig_<em>${language}</em>_ <em>${graph_type}</em>-instances_political_orientation_mapping.nt.bz2 			</td> 			<td> 			Mapping of news outlets instances to political orientation classes. 			</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_content_literals.nt.bz2</td> 			<td>Relations between content instances and corresponding literals (e.g. text of title, abstract, body).</td> 		</tr> 		<tr> 			<td> 			nemig_<em>${language}_ ${graph_type}</em>-instances_sentiment_polorient_literals.nt.bz2 			</td> 			<td> 			Relations between instances and corresponding sentiment or political orientation literals. 			</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_metadata_resources.nt.bz2</td> 			<td>Relations between news or sub-topic instances and entities extracted from metadata (i.e. publishers, authors, keywords).</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-instances_event_mapping.nt.bz2</td> 			<td>Mapping of news instances to event instances.</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-event_resources.nt.bz2</td> 			<td>Relations between event instances and entities extracted from the text of the news (i.e. actors, places, mentions).</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-resources_provenance.nt.bz2</td> 			<td>Provenance information about the entities extracted from the text of the news (e.g. title, abstract, body).</td> 		</tr> 		<tr> 			<td>nemig_<em>$</em>{<em>language}</em>_ <em>$</em>{<em>graph_type}</em>-wiki_resources.nt.bz2</td> 			<td>Relations between Wikidata entities from news and their&nbsp;<em>k</em>-hop entity neighbors from Wikidata.</td> 		</tr> 	</tbody> </table>  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  The corresponding user data has been collected through online studies in Germany and the US. We used the participants&#39; implicit feedback regarding their interest in an article to build their click history, and the explicit feedback in terms of news click behaviors to construct the impression logs. To protect user privacy, we assign each user an anonymized ID.  The German and English user datasets&nbsp;are zip-compressed folders, which contain&nbsp;two files each.  <table> 	<caption>NeMig User Dataset File Description</caption> 	<tbody> 		<tr> 			<td><strong>File</strong></td> 			<td><strong>Description</strong></td> 		</tr> 		<tr> 			<td> 			behaviors.tsv 			</td> 			<td> 			The click history and impression logs of users. 			</td> 		</tr> 		<tr> 			<td> 			demographics_politics.tsv 			</td> 			<td> 			Demographic and political information of users. 			</td> 		</tr> 	</tbody> </table>  The <strong>behaviors.tsv</strong> file contains the users&#39; news click histories and the impression logs. It has 4 columns divided by the tab symbol:  <ul> 	<li> 	Impression ID: the ID of an impression. 	</li> 	<li> 	User ID: The anonymized ID of an user. 	</li> 	<li> 	Click History: The news click history (list of news IDs) of a user before an impression. 	</li> 	<li> 	Impression Log: List of news displayed to the user in a session and the user&#39;s click behavior on them (1 for click, 0 for non-click). 	</li> </ul>  The <strong>demographics_politics.tsv</strong> file contains detailed information about the users&#39; demographics and political interests. It has columns divided by the tab symbol. An explanation of all the columns and the questions used in the online studies to collect this information is shown in the table below.  <table> 	<caption>Demographic and political user data description</caption> 	<thead> 		<tr> 			<th scope=""col"">Column Name</th> 			<th scope=""col"">Question in German study</th> 			<th scope=""col"">Scale in German</th> 			<th scope=""col"">Question in English study</th> 			<th scope=""col"">Scale in English</th> 		</tr> 	</thead> 	<tbody> 		<tr> 			<td><strong>Demographics</strong></td> 			<td>&nbsp;</td> 			<td>&nbsp;</td> 			<td>&nbsp;</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>Gender</td> 			<td>Bitte geben Sie Ihr Geschlecht an</td> 			<td>0 = m&auml;nnlich<br> 			1 = weiblich<br> 			2 = divers<br> 			3 = Keine Angabe</td> 			<td>Please indicate your gender.</td> 			<td>0 = male<br> 			1 = female<br> 			2 = other<br> 			3 = no answer</td> 		</tr> 		<tr> 			<td>Age</td> 			<td>Bitte geben Sie Ihr Alter an&nbsp;&nbsp; &nbsp;</td> 			<td>1-120</td> 			<td>Please indicate your age.</td> 			<td>1-120</td> 		</tr> 		<tr> 			<td>Qualification</td> 			<td>Welches ist Ihr h&ouml;chster Bildungsabschluss?</td> 			<td>0 = Kein Schulabschluss<br> 			1 = Haupt-/Gesamtschulabschluss<br> 			2 = Realschulabschluss, Mittlere Reife, Fachschulreife<br> 			3 = Fachhochschulreife, Abitur<br> 			4 = Studium mit Abschluss<br> 			5 = Promotion<br> 			6 = Keine Angabe</td> 			<td>Please indicate your highest educational qualification.</td> 			<td>0 = less than high school<br> 			1 = high school/GED<br> 			2 = Vo-tech/business school<br> 			3 = some college<br> 			4 = college degree<br> 			5 = university degree<br> 			6 = doctoral degree<br> 			7 = no answer</td> 		</tr> 		<tr> 			<td>Nationality</td> 			<td>Welche Staatsangeh&ouml;rigkeit besitzen Sie?</td> 			<td>0 = Nur die deutsche Staatsangeh&ouml;rigkeit<br> 			1 = Die deutsche und eine andere Staatsangeh&ouml;rigkeit<br> 			2 = Nur eine andere Staatsangeh&ouml;rigkeit<br> 			3 = Keine Angabe</td> 			<td>What is your citizenship?</td> 			<td>0 = U.S. citizenship<br> 			1 = U.S. and another non-U.S. citizenship<br> 			2 = Only non-U.S. citizenship<br> 			3 = No Answer</td> 		</tr> 		<tr> 			<td>BornIn</td> 			<td>Sind Sie in Deutschland geboren?</td> 			<td>0 = Ja<br> 			1 = Nein<br> 			2 = Keine Angabe</td> 			<td>Were you born in the U.S.?</td> 			<td>0 = Yes<br> 			1 = No<br> 			2 = No answer</td> 		</tr> 		<tr> 			<td>ParentsBornIn</td> 			<td>Sind Ihre Eltern in Deutschland geboren?</td> 			<td>0 = Mein Vater und meine Mutter sind beide in Deutschland geboren<br> 			1 = Mein Vater ist in Deutschland geboren, meine Mutter nicht<br> 			2 = Meine Mutter ist in Deutschland geboren, mein Vater nicht<br> 			3 = Weder meine Mutter noch mein Vater sind in Deutschland geboren<br> 			4 = Keine Angabe</td> 			<td>Were your parents born in the U.S.?</td> 			<td>0 = My father and my mother were both born in the U.S.<br> 			1 = My father was born in the U.S., my mother was not<br> 			2 = My mother was born in the U.S., my father was not<br> 			3 = Neither my mother nor my father were born in the U.S<br> 			4 = No answer</td> 		</tr> 		<tr> 			<td>Income</td> 			<td>Was ist Ihr pers&ouml;nliches monatliches Nettoeinkommen (nach Abzug der Steuern)? Bitte geben Sie eine ungef&auml;hre Sch&auml;tzung an, falls Sie die genaue Zahl nicht kennen.</td> 			<td>0 = Weniger als 1000 &euro;<br> 			1 = 1001 &euro; bis 2000 &euro;<br> 			2 = 2001 &euro; bis 3000 &euro;<br> 			3 = 3001 &euro; bis 4000 &euro;<br> 			4 = 4001 &euro; bis 5000 &euro;<br> 			5 = Mehr als 5000 &euro;<br> 			6 = Keine Angabe</td> 			<td>What is your personal monthly net income (after taxes)? Please give an approximate estimation in case you are unsure.</td> 			<td>0 = Less than 1000 $<br> 			1 = 1001 $ to 2000 $<br> 			2 = 2001 $ to 3000 $<br> 			3 = 3001 $ to 4000 $<br> 			4 = 4001 $ to 5000 $<br> 			5 = More than 5000 $<br> 			6 = No Answer</td> 		</tr> 		<tr> 			<td><strong>Empathy</strong></td> 			<td><strong>Wie sehr stimmen Sie den folgenden Aussagen zu?</strong></td> 			<td> 			<strong>7-point Likert scale</strong>  			<strong>1=Trifft &uuml;berhaupt nicht zu<br> 			7=Trifft voll und ganz zu</strong> 			</td> 			<td><strong>How strongly do you agree with the following statements?</strong></td> 			<td><strong>7-point Likert scale<br> 			<br> 			1=Strongly disagree<br> 			7=Strongly agree</strong></td> 		</tr> 		<tr> 			<td>EMP1</td> 			<td>Wenn jemand anderes erfreut ist, tendiere ich dazu auch erfreut zu sein.</td> 			<td>&nbsp;</td> 			<td>When someone else is feeling excited, I tend to get excited too.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP2</td> 			<td>Es regt mich auf, wenn jemand respektlos behandelt wird.</td> 			<td>&nbsp;</td> 			<td>It upsets me to see someone being treated disrespectfully.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP3</td> 			<td>Es macht mir Freude, andere aufzumuntern.</td> 			<td>&nbsp;</td> 			<td>I enjoy making other people feel better.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP4</td> 			<td>Ich bin besorgt um Personen, die weniger Gl&uuml;ck haben als ich.</td> 			<td>&nbsp;</td> 			<td>I have tender, concerned feelings for people less fortunate than me.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP5</td> 			<td>Ich f&uuml;hle, wenn andere traurig sind, selbst wenn sie nichts sagen.</td> 			<td>&nbsp;</td> 			<td>I can tell when others are sad even when they do not say anything.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP6</td> 			<td>Meistens bin ich mit den Stimmungen anderer Leute im Einklang.</td> 			<td>&nbsp;</td> 			<td>I find that I am &ldquo;in tune&rdquo; with other people&rsquo;s moods.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP7</td> 			<td>Ich empfinde einen starken Drang zu helfen, wenn ich jemanden sehe, der aufgebracht ist.</td> 			<td>&nbsp;</td> 			<td>I get a strong urge to help when I see someone who is upset.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMP8</td> 			<td>Wenn ich jemanden sehe, der ausgenutzt wird, m&ouml;chte ich die Person besch&uuml;tzen.</td> 			<td>&nbsp;</td> 			<td>When I see someone being taken advantage of, I feel kind of protective towards him\her.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Big5</strong></td> 			<td><strong>Ich bin...</strong></td> 			<td> 			<strong>7-point Likert scale</strong>  			<strong>0 = Sehr<br> 			1 = Ziemlich<br> 			2 = Etwas<br> 			3 = Teils=Teils<br> 			4 = Etwas<br> 			5 = Zeimlich<br> 			6 = Sehr</strong> 			</td> 			<td><strong>I see myself as...</strong></td> 			<td> 			<strong>7-point Likert scale</strong>  			<strong>1=Strongly disagree<br> 			7=Strongly agree</strong> 			</td> 		</tr> 		<tr> 			<td>BIG1</td> 			<td>extrovertiert -- introvertiert</td> 			<td>&nbsp;</td> 			<td>...extroverted, enthusiastic</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG2</td> 			<td>emotional -- ausgeglichen</td> 			<td>&nbsp;</td> 			<td>...critical, quarrelsome</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG3</td> 			<td>aufgeschlossen -- festgelegt</td> 			<td>&nbsp;</td> 			<td>...dependable, self-disciplined</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG4</td> 			<td>barsch -- umg&auml;nglich</td> 			<td>&nbsp;</td> 			<td>...anxious, easily upset</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG5</td> 			<td>gewissenhaft -- nachl&auml;ssig</td> 			<td>&nbsp;</td> 			<td>...open to new experiences, complex</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG6</td> 			<td>-</td> 			<td>&nbsp;</td> 			<td>...reserved, quiet</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG7</td> 			<td>-</td> 			<td>&nbsp;</td> 			<td>...sympathetic, warm</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG8</td> 			<td>-</td> 			<td>&nbsp;</td> 			<td>...disorganized, careless</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG9</td> 			<td>-</td> 			<td>&nbsp;</td> 			<td>..calm, emotionally stable</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>BIG10</td> 			<td>-</td> 			<td>&nbsp;</td> 			<td>...conventional, uncreative</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Ideological Polarization</strong></td> 			<td><strong>Im Folgenden sehen Sie eine Reihe von gegens&auml;tzlichen Aussagen.<br> 			Bitte geben Sie jeweils an, wie sehr Sie der Aussage zustimmen oder diese ablehnen.<br> 			Es gibt keine richtigen oder falschen Antworten.</strong></td> 			<td> 			<strong>7-point Likert scale</strong>  			<strong>0 = Sehr<br> 			1 = Ziemlich<br> 			2 = Etwas<br> 			3 = Teils=Teils<br> 			4 = Etwas<br> 			5 = Zeimlich<br> 			6 = Sehr</strong> 			</td> 			<td><strong>In the following, you will see a series of opposing statements.<br> 			Please indicate how strongly you agree or disagree with the statements.<br> 			There are no right or wrong answers.</strong></td> 			<td> 			<strong>7-point Likert scale</strong>  			<strong>1=Strongly disagree<br> 			7=Strongly agree</strong> 			</td> 		</tr> 		<tr> 			<td>IPO1</td> 			<td>Deutschland sollte mehr Gefl&uuml;chtete aufnehmen.</td> 			<td>&nbsp;</td> 			<td>The U.S. should take in more refugees.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO2</td> 			<td>Deutschland hat schon zu viele Fl&uuml;chtlinge aufgenommen.</td> 			<td>&nbsp;</td> 			<td>The U.S. should take in more refugees.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO3</td> 			<td>Deutschland sollte sich f&uuml;r sichere und einfache Fluchtwege nach Europa einsetzen.</td> 			<td>&nbsp;</td> 			<td>The U.S. should advocate safe and easy escape routes to North America.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO4</td> 			<td>Deutschland sollte sich daf&uuml;r einsetzen, dass Fl&uuml;chtlinge nicht einfach nach Europa kommen k&ouml;nnen.</td> 			<td>&nbsp;</td> 			<td>The U.S. should work to ensure that refugees cannot easily come to North America.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO5</td> 			<td>Immigranten bem&uuml;hen sich um ein friedliches Zusammenleben mit Deutschen.</td> 			<td>&nbsp;</td> 			<td>Immigrants strive for peaceful cohabitation with U.S.-Americans.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO6</td> 			<td>Immigranten treten den Deutschen feindselig gegen&uuml;ber.</td> 			<td>&nbsp;</td> 			<td>Immigrants are hostile toward U.S.-Americans.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO7</td> 			<td>Immigranten wollen auf Kosten des deutschen Wohlstands leben.</td> 			<td>&nbsp;</td> 			<td>Immigrants want to live at the expense of U.S.-American prosperity.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO8</td> 			<td>Immigranten helfen dabei, den deutschen Wohlstand zu sichern.</td> 			<td>&nbsp;</td> 			<td>Immigrants help in securing U.S.-American prosperity.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO9</td> 			<td>Immigranten bedrohen die deutsche Kultur und Lebensweise.</td> 			<td>&nbsp;</td> 			<td>Immigrants threaten the U.S.-American culture and lifestyle.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO10</td> 			<td>Immigranten bereichern die deutsche Kultur und Lebensweise.</td> 			<td>&nbsp;</td> 			<td>Immigrants enrich the U.S.-American culture and lifestyle.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO11</td> 			<td>Immigranten sind krimineller und gewaltt&auml;tiger als Deutsche.</td> 			<td>&nbsp;</td> 			<td>Immigrants are more criminal and more violent than U.S.-Americans.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>IPO12</td> 			<td>Immigranten sind nicht krimineller oder gewaltt&auml;tiger als Deutsche.</td> 			<td>&nbsp;</td> 			<td>Immigrants are not more criminal and violent than U.S.-Americans.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Emotions</strong></td> 			<td><strong>Welche Emotionen empfinden Sie gegen&uuml;ber Gefl&uuml;chteten und Immigranten in Deutschland?</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1 = Stimme &uuml;berhaupt nicht zu<br> 			7 = Stimme voll zu</strong></td> 			<td><strong>Which emotions do you feel towards refugees and immigrants in the USA?</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1=Strongly disagree<br> 			7=Strongly agree</strong></td> 		</tr> 		<tr> 			<td>EMO1</td> 			<td>Wut</td> 			<td>&nbsp;</td> 			<td>Anger</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO2</td> 			<td>Angst</td> 			<td>&nbsp;</td> 			<td>Fear</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO3</td> 			<td>Verachtung</td> 			<td>&nbsp;</td> 			<td>Contempt</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO4</td> 			<td>Trauer</td> 			<td>&nbsp;</td> 			<td>Grief</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO5</td> 			<td>Ekel</td> 			<td>&nbsp;</td> 			<td>Disgust</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO6</td> 			<td>Neid</td> 			<td>&nbsp;</td> 			<td>Envy</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO7</td> 			<td>Schadenfreude</td> 			<td>&nbsp;</td> 			<td>Gloat</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO8</td> 			<td>Mitleid</td> 			<td>&nbsp;</td> 			<td>Pity</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO9</td> 			<td>Mitgef&uuml;hl</td> 			<td>&nbsp;</td> 			<td>Compassion</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO10</td> 			<td>Bewunderung</td> 			<td>&nbsp;</td> 			<td>Admiration</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO11</td> 			<td>Freude</td> 			<td>&nbsp;</td> 			<td>Joy</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO12</td> 			<td>Hoffnung</td> 			<td>&nbsp;</td> 			<td>Hope</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO13</td> 			<td>Dankbarkeit</td> 			<td>&nbsp;</td> 			<td>Gratitude</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>EMO14</td> 			<td>Ehrfurcht</td> 			<td>&nbsp;</td> 			<td>Awe</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Media Usage</strong></td> 			<td><strong>Informationen &uuml;ber die deutsche Politik bekomme ich aus/von:</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1=Nie<br> 			7=Sehr h&auml;ufig</strong></td> 			<td><strong>I receive information about US-American politics via:</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1=Never<br> 			7=Very Often</strong></td> 		</tr> 		<tr> 			<td>MED1</td> 			<td>Zeitungen und Magazinen oder deren Internet-Angeboten (z.B. BILD-Zeitung/ bild.de, Der Spiegel/spiegel.de, ...)&nbsp;&nbsp; &nbsp;</td> 			<td>&nbsp;</td> 			<td>newspapers and magazines or their websites (e.g. New York Times, The Wallstreet Journal, ...)</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED2</td> 			<td>dem Fernsehen oder deren Internet-Angeboten (z.B. ARD/ard.de, RTL /rtl.de, ...)</td> 			<td>&nbsp;</td> 			<td>TV networks or their websites (e.g. Fox News, CNN... )</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED3</td> 			<td>dem Radio deren Internet-Angeboten (z.B. Energy/energy.de, Deutschlandfunk/deutschlandfunk.de, &hellip;)&nbsp;&nbsp; &nbsp;</td> 			<td>&nbsp;</td> 			<td>radio stations or their websites (e.g. WHTZ-FM, KIIS-FM, &hellip; )</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED4</td> 			<td>Facebook (zur politischen Information)</td> 			<td>&nbsp;</td> 			<td>Facebook (for political information)</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED5</td> 			<td>Twitter (zur politischen Information)</td> 			<td>&nbsp;</td> 			<td>Twitter (for political information)</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED6</td> 			<td>Instagram (zur politischen Information)</td> 			<td>&nbsp;</td> 			<td>Instagram (for political information)</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED7</td> 			<td>Messenger Diensten wie z.B. WhatsApp und Telegram (zur politischen Information)</td> 			<td>&nbsp;</td> 			<td>messenger services such as WhatsApp or Telegram (for political information)</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED8</td> 			<td>YouTube (zur politischen Information)</td> 			<td>&nbsp;</td> 			<td>YouTube (for political information)</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>MED9</td> 			<td>Politischen Blogs und/oder speziellen Nachrichtenanbietern, die es nur im Internet gibt</td> 			<td>&nbsp;</td> 			<td>political blogs and/or alternative news providers, which can only be found online</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Participation</strong></td> 			<td><strong>K&ouml;nnen Sie sich vorstellen, in naher Zukunft&hellip;</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1=Kann ich mir gar nicht vorstellen<br> 			<br> 			7=Kann ich mir gar nicht vorstellen</strong></td> 			<td><strong>Please indicate how likely it is that you will engage in the following activities in the near future.</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1=Not likely at all<br> 			<br> 			7=Very likely</strong></td> 		</tr> 		<tr> 			<td>PPA1</td> 			<td>&hellip; an einer politische Onlinediskussion zum Thema Immigration in Deutschland teilzunehmen?</td> 			<td>&nbsp;</td> 			<td>Participating in an online political discussion on the topic of immigration to the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA2</td> 			<td>&hellip; eine politische Onlinepetition zum Thema Immigration in Deutschland zu unterschreiben?</td> 			<td>&nbsp;</td> 			<td>Signing an online political petition on the topic of immigration to the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA3</td> 			<td>&hellip; eine/n Politiker/in in Deutschland zum Thema Immigration mit einer E-Mail oder &uuml;ber Social Media zu kontaktieren?</td> 			<td>&nbsp;</td> 			<td>Contacting a U.S.-American politician on the topic of immigration via e-mail or social media.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA4</td> 			<td>&hellip; einer politischen Partei oder Gruppe auf Social Media zu folgen, die sich besonders im Themenfeld Immigration in Deutschland engagiert?</td> 			<td>&nbsp;</td> 			<td>Following a party or group on social media, that is particularly engaged in the field of immigration to the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA5</td> 			<td>&hellip; einer politischen Partei oder Gruppe Geld zu spenden, die sich besonders im Themenfeld Immigration in Deutschland engagiert?</td> 			<td>&nbsp;</td> 			<td>Donating money to a political party or group that is especially involved in the field of immigration to the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA6</td> 			<td>&hellip; an einer politischen Demonstration zum Thema Immigration in Deutschland teilzunehmen?</td> 			<td>&nbsp;</td> 			<td>Participating in a political demonstration on the topic of immigration to the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA7</td> 			<td>&hellip; einer politischen Partei oder einer Gruppe beizutreten, die sich besonders im Themenfeld Immigration in Deutschland engagiert?</td> 			<td>&nbsp;</td> 			<td>Joining a political party or group that is especially involved in the field of immigration to the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PPA8</td> 			<td>&hellip; f&uuml;r eine politische Partei, oder einer Gruppe Freiwilligenarbeit zu leisten, die sich besonders im Themenfeld Immigration in Deutschland engagiert?</td> 			<td>&nbsp;</td> 			<td>Volunteering for a political party or group that is especially involved in the field of immigration.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Perceived Polarization</strong></td> 			<td><strong>Wie bewerten Sie folgende Aussagen?</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1 = Stimme &uuml;berhaupt nicht zu<br> 			7 = Stimme voll zu</strong></td> 			<td><strong>How strongly do you agree or disagree with the following statements?</strong></td> 			<td> 			<strong>7-point Likert Scale</strong>  			<strong>1=Strongly disagree<br> 			7=Strongly agree</strong> 			</td> 		</tr> 		<tr> 			<td>PRO1</td> 			<td>Die Anh&auml;nger der verschiedenen politischen Parteien in Deutschland stehen sich immer feindseliger gegen&uuml;ber.</td> 			<td>&nbsp;</td> 			<td>Democratic and Republican partisans in the U.S. are increasingly hostile to one another.&nbsp;&nbsp; &nbsp;</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PRO2</td> 			<td>Die Anh&auml;nger der verschiedenen politischen Parteien in Deutschland haben sich immer weniger zu sagen.</td> 			<td>&nbsp;</td> 			<td>There is less and less common meeting ground between Democratic and Republican partisans in the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PRO3</td> 			<td>Die Anh&auml;nger der verschiedenen politischen Parteien in Deutschland sind sehr polarisiert.</td> 			<td>&nbsp;</td> 			<td>Democratic and Republican partisans in the U.S. are very polarized.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PRO4</td> 			<td>Die Meinungen zum Thema Immigration gehen in der deutschen Bev&ouml;lkerung immer weiter auseinander.</td> 			<td>&nbsp;</td> 			<td>Opinions about immigration issues are increasingly diverging in U.S. society.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PRO5</td> 			<td>Es wird immer schwieriger, in der deutschen Bev&ouml;lkerung Einigung zu Fragen der Immigration zu erreichen.</td> 			<td>&nbsp;</td> 			<td>It is becoming increasingly difficult to reach agreement on immigration issues among the U.S. population.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PRO6</td> 			<td>Das Thema Immigration spaltet die Menschen in Deutschland.</td> 			<td>&nbsp;</td> 			<td>Immigration issues are dividing the people in the U.S.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Affective polarization</strong></td> 			<td><strong>Hier sehen Sie die Liste aller im Bundestag vertretenen Parteien.<br> 			Bitte markieren Sie auf jeder der Skalen wie positiv oder negativ Sie f&uuml;r die jeweilige Partei empfinden.</strong></td> 			<td><strong>0 (negative) to 100 (positive)</strong></td> 			<td><strong>In the following we would like to know about your party identification.<br> 			Please mark on the scale how warm or cold you feel towards the respective parties.</strong></td> 			<td><strong>0 (negative) to 100 (positive)</strong></td> 		</tr> 		<tr> 			<td>CDU / Rep</td> 			<td>CDU</td> 			<td>&nbsp;</td> 			<td>Republican&nbsp;&nbsp; &nbsp;</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>SPD / Dem</td> 			<td>SPD</td> 			<td>&nbsp;</td> 			<td>Democrat</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>GRU</td> 			<td>GRU</td> 			<td>&nbsp;</td> 			<td>-</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>FDP</td> 			<td>FDP</td> 			<td>&nbsp;</td> 			<td>-</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>LIN</td> 			<td>LIN</td> 			<td>&nbsp;</td> 			<td>-</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>AFD</td> 			<td>AFD</td> 			<td>&nbsp;</td> 			<td>-</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Political Scale</strong>&nbsp;(POL1)</td> 			<td><strong>Wo w&uuml;rden Sie Ihren eigenen politischen Standpunkt auf der folgenden Skala einordnen?</strong></td> 			<td><strong>11-point Likert Scale<br> 			<br> 			1 = Links<br> 			6 = Mitte<br> 			11 = Rechts</strong></td> 			<td><strong>Where on the scale would you place your political point of view?</strong></td> 			<td><strong>11-point Likert Scale<br> 			<br> 			1 = Left<br> 			6 = Center<br> 			11 = Right</strong></td> 		</tr> 		<tr> 			<td><strong>Political Topics</strong></td> 			<td><strong>Bitte geben Sie an, inwiefern die folgenden Aussagen auf Sie zutreffen?</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1 = Trifft &uuml;berhaupt nicht zu<br> 			7 = Trifft voll und ganz zu</strong></td> 			<td><strong>Please indicate how strongly you agree or disagree with the following statements.</strong></td> 			<td><strong>7-point Likert Scale<br> 			<br> 			1 = Strongly disagree<br> 			7 = Strongly agree</strong></td> 		</tr> 		<tr> 			<td>POL2</td> 			<td>Ich interessiere mich im Allgemeinen sehr f&uuml;r Politik.</td> 			<td>&nbsp;</td> 			<td>I am generally very interested in politics.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL3</td> 			<td>Ich informiere mich regelm&auml;&szlig;ig &uuml;ber das aktuelle politische Geschehen in Deutschland.</td> 			<td>&nbsp;</td> 			<td>I regularly inform myself about current political affairs in the U.S..</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL4</td> 			<td>Mir ist es wichtig, &uuml;ber das aktuelle politische Geschehen in Deutschland informiert zu sein.</td> 			<td>&nbsp;</td> 			<td>It is important to me to be informed about current political affairs in the U.S..</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL5</td> 			<td>Ich lese viele politische Nachrichtenartikel.</td> 			<td>&nbsp;</td> 			<td>I read many political news articles.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL6</td> 			<td>Im Vergleich zu meinen Freunden bin ich ein Experte f&uuml;r das aktuelle politische Geschehen.</td> 			<td>&nbsp;</td> 			<td>Compared to my friends, I am an expert on current political affairs.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL7</td> 			<td>Ich interessiere mich sehr f&uuml;r das Thema Immigration und die Immigrationspolitik in Deutschland.</td> 			<td>&nbsp;</td> 			<td>I am very interested in the topic of immigration and U.S. immigration policy.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL8</td> 			<td>Ich informiere mich regelm&auml;&szlig;ig &uuml;ber Neuigkeiten zum Thema Immigration und Immigrationspolitik in Deutschland.</td> 			<td>&nbsp;</td> 			<td>I try to keep up-to-date with news about immigration and U.S. immigration policy.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>POL9</td> 			<td>Mir ist es wichtig, &uuml;ber die aktuellen Entwicklungen zum Thema Immigration und Immigrationspolitik in Deutschland informiert zu sein.</td> 			<td>&nbsp;</td> 			<td>It is important to me to be informed about current developments in the field of immigration and U.S. immigration policy.</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td><strong>Prosocial behavior</strong></td> 			<td><strong>Bitte geben Sie nachfolgend an wie sehr Sie den Aussagen zustimmen.</strong></td> 			<td>&nbsp;</td> 			<td><strong>Please indicate how strongly you agree or disagree with the following statements.&nbsp;</strong>&nbsp; &nbsp;</td> 			<td>&nbsp;</td> 		</tr> 		<tr> 			<td>PRO1</td> 			<td>Ich w&auml;re bereit, Gegenst&auml;nde (z. B. Kleidung, Spielzeug, M&ouml;bel, Elektroger&auml;te) f&uuml;r Gefl&uuml;chtete in Deutschland zu spenden.</td> 			<td>7-point Likert Scale<br> 			<br> 			1 = Stimme &uuml;berhaupt nicht zu<br> 			7 = Stimme voll zu</td> 			<td>I would be willing to donate items (e.g. clothing, toys, furniture, electronics) to refugees living in the U.S.</td> 			<td>7-point Likert Scale<br> 			<br> 			1 = Strongly disagree<br> 			7 = Strongly agree</td> 		</tr> 		<tr> 			<td>PRO2</td> 			<td>Ich w&auml;re dazu bereit, Gefl&uuml;chtete im Alltag zu unterst&uuml;tzen (z. B. Beh&ouml;rdeng&auml;nge begleiten, Deutschunterricht geben, eine gemeinsame Freizeitaktivit&auml;t unternehmen).</td> 			<td>7-point Likert Scale<br> 			<br> 			1 = Stimme &uuml;berhaupt nicht zu<br> 			7 = Stimme voll zu</td> 			<td>I would be willing to support refugees living in the U.S. with their everyday life (e.g. support with bureaucratic procedures, teaching English, leisure activities).</td> 			<td>7-point Likert Scale<br> 			<br> 			1 = Strongly disagree<br> 			7 = Strongly agree</td> 		</tr> 		<tr> 			<td>PRO3</td> 			<td>Ich w&auml;re bereit __ &euro; f&uuml;r Gefl&uuml;chtete in Deutschland zu spenden.</td> 			<td>float number &gt;= 0</td> 			<td>I am willing to make a one-time donation of __$ for refugees in the U.S.</td> 			<td>float number &gt;= 0</td> 		</tr> 		<tr> 			<td>PRO4</td> 			<td>Wie h&auml;ufig haben Sie beruflich (z. B. auf der Arbeit, im Studium) Kontakt mit Menschen mit Migrationshintergrund?</td> 			<td> 			7-point Likert Scale  			1 = Nie<br> 			7 = Sehr h&auml;ufig 			</td> 			<td>How often do you have professional contact (e.g. at work or at school) with immigrants?</td> 			<td> 			7-point Likert Scale  			1 = Never<br> 			7 = Very often 			</td> 		</tr> 		<tr> 			<td>PRO5</td> 			<td>Wie h&auml;ufig haben Sie privat (z. B. Freunde, Verwandte, Bekannte) Kontakt mit Menschen mit Migrationshintergrund?</td> 			<td> 			7-point Likert Scale  			1 = Nie<br> 			7 = Sehr h&auml;ufig 			</td> 			<td>How often do you have private contact (e.g. friends, relatives, acquaintances) with immigrants?</td> 			<td> 			7-point Likert Scale  			1 = Never<br> 			7 = Very often 			</td> 		</tr> 	</tbody> </table>  &nbsp;","Iana, Andreea, Alam, Mehwish, Grote, Alexander, Nikolajevic, Nevena, Ludwig, Katharina, Müller, Philipp, Weinhardt, Christof, Paulheim, Heiko",dataset,,https://zenodo.org/records/7908392
10.5281/zenodo.485151,Unsupervised Does Not Mean Uninterpretable: The Case for Word Sense Induction and Disambiguation,2017-04-01,"This dataset contains the models for interpretable Word Sense Disambiguation (WSD) that were employed in Panchenko et al. (2017; the paper can be accessed at https://www.lt.informatik.tu-darmstadt.de/fileadmin/user_upload/Group_LangTech/publications/EACL_Interpretability___FINAL__1_.pdf).  The files were computed on a 2015 dump from the English Wikipedia. Their contents:  <ul> 	<li>Induced Sense Inventories: <strong>wp_stanford_sense_inventories.tar.gz</strong><br> 	This file contains 3 inventories (coarse, medium fine)</li> 	<li>Language Model (3-gram): <strong>wiki_text.3.arpa.gz</strong><br> 	This file contains all n-grams up to n=3 and can be loaded into an index</li> 	<li>Weighted Dependency Features: <strong>wp_stanford_lemma_LMI_s0.0_w2_f2_wf2_wpfmax1000_wpfmin2_p1000.gz</strong><br> 	This file contains weighted word--context-feature combinations and includes their count and an LMI significance score</li> 	<li>Distributional Thesaurus (DT) of Dependency Features: <strong>wp_stanford_lemma_BIM_LMI_s0.0_w2_f2_wf2_wpfmax1000_wpfmin2_p1000_simsortlimit200_feature expansion.gz</strong><br> 	This file contains a DT of context features. The context feature similarities can be used for context expansion</li> </ul>  For further information, consult the paper and the companion page: http://jobimtext.org/wsd/  Panchenko A., Ruppert E., Faralli S., Ponzetto S. P., and Biemann C. (2017): Unsupervised Does Not Mean Uninterpretable: The Case for Word Sense Induction and Disambiguation. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL'2017). Valencia, Spain. Association for Computational Linguistics.      ","Panchenko, Alexander, Ruppert, Eugen, Faralli, Stefano, Ponzetto, Simone Paolo, Biemann, Chris",dataset,cc-by-4.0,https://zenodo.org/records/485151
10.5281/zenodo.2621579,Datasets for Watset: Local-Global Graph Clustering with Applications in Sense and Frame Induction,2019-04-02,"This dataset supplements the article &ldquo;<a href=""https://doi.org/10.1162/COLI_a_00354"">Watset: Local-Global Graph Clustering with Applications in Sense and Frame Induction</a>&rdquo; published in&nbsp;the Computational Linguistics journal:  <ul> 	<li> 	<code>watset-coli-lcc-performance.tsv</code>: runtime analysis 	</li> 	<li> 	<code>watset-coli-synsets.zip</code>: synset induction experiment (note that&nbsp;<code>pairwise-{en-babelnet,ru-rwn}.pkl</code> files are excluded due to the licensing&nbsp;issues) 	</li> 	<li> 	<code>watset-coli-triframes.zip</code>: semantic frame induction experiment 	</li> 	<li> 	<code>watset-coli-classes.zip</code>: semantic class induction experiment 	</li> </ul>","Ustalov, Dmitry, Panchenko, Alexander, Biemann, Chris, Ponzetto, Simone Paolo",dataset,cc-by-4.0,https://zenodo.org/records/2621579
10.5281/zenodo.10794394,"lab.js: A free, open, online experiment builder",2024-03-07,"<strong>lab.js makes it easy to build experiments for both online and in-laboratory data collection.</strong>. It provides a visual interface for constructing studies, and a powerful Javascript library for stimulus presentation and response collection.","Henninger, Felix, Shevchenko, Yury, Mertens, Ulf, Kieslich, Pascal J., Hilbig, Benjamin E.",software,cc-by-4.0,https://zenodo.org/records/10794394
10.5281/zenodo.5862646,kristiankolthoff/PMMC-Evaluator: v1.0,2022-01-17,Evaluation metrics and results for the Process Model Matching Contest (PMMC),Kristian Kolthoff,software,other-open,https://zenodo.org/records/5862646
10.5281/zenodo.11567179,liserman/archiveRetriever: archiveRetriever 0.4.0,2024-06-11,"<h1>archiveRetriever 0.4.0</h1> <ul> <li>Replace deprecated functions of dependencies</li> <li>Fix bugs in <em>archive_overview()</em> and <em>retrieve_urls()</em></li> <li>New option <em>nonArchive</em> added to <em>retrieve_links()</em> and <em>scrape_urls()</em>. This option allows users to scrape internet pages not stemming from the Internet Archive.</li> <li>New feature added to the <em>collapse</em> option of <em>scrape_urls()</em>. <em>collapse</em> can now also take a Xpath as input, to collapse results based on a structuring Xpath. Unfortunately, this works only with Xpaths and not with CSS selectors. If used, <em>Paths</em> refers only to children of the structuring Xpath given in <em>collapse</em>.</li> </ul>","Lukas Isermann, Konstantin Gavras, Gwendolyn Mingham",software,cc-by-4.0,https://zenodo.org/records/11567179
10.5281/zenodo.15368485,Generated synthetic graphs for runtime comparison for RDF2Vec packages,2025-05-09,,"Boeckling, Martin",dataset,cc-by-4.0,https://zenodo.org/records/15368485
10.5281/zenodo.4280543,JKHoehne/SImage: First releases of SImage,2020-11-19,This is the initial release,"Konstantin Gavras, JKHoehne",software,other-open,https://zenodo.org/records/4280543
10.5281/zenodo.3247311,Multi-attribute task builder,2019-06-17,"We have created the&nbsp;Multi-Attribute Decision (MAD) builder&nbsp;for researchers to help to design a Mouselab task in a browser-based experiment. The MAD builder is available as either a template in the&nbsp;<a href=""https://labjs.felixhenninger.com/"">lab.js</a>&nbsp;or as a complete task in&nbsp;<a href=""https://open-lab.online/"">Open Lab</a>.&nbsp;",Shevchenko Yury,software,cc-by-4.0,https://zenodo.org/records/3247311
10.5281/zenodo.838978,danheck/MCMCprecision: CRAN release,2017-08-04,Mostly cosmetic polishing.,Daniel Heck,software,other-open,https://zenodo.org/records/838978
10.5281/zenodo.838981,danheck/metaBMA: CRAN release,2017-08-04,Minor bug fixes.,Daniel Heck,software,other-open,https://zenodo.org/records/838981
10.5281/zenodo.7097560,cosimameyer/overviewR: JOSS paper archival (updated),2022-09-20,This release entails all changes requested by reviewers at JOSS: <ul> <li>Added overview table that puts <code>overviewR</code> in perspective with other R packages (in README)</li> <li>Make code visible how to generate modified <code>toydata</code> data sets (in README)</li> <li>Rename <code>overview_print</code> to <code>overview_latex</code></li> <li>Deprecate separate <code>file</code> and <code>path</code> arguments in <code>overview_latex</code> and add <code>file_path</code> instead</li> <li>It also includes the paper and all accompanying material in <code>paper/</code></li> <li>In contrast to <code>v0.0.12</code> we also removed the footnote from the institution</li> </ul>,"Cosima Meyer, Dennis Hammerschmidt",software,other-open,https://zenodo.org/records/7097560
10.5281/zenodo.15538250,keyvan-amiri/UQ4PPM: UQ4PPM-1st-Release,2025-05-28,The github repository for our paper: &quot;A Simple and Calibrated Approach for Uncertainty-Aware Remaining Time Prediction&quot;,Keyvan Amiri Elyasi,software,mit-license,https://zenodo.org/records/15538250
10.5281/zenodo.4644590,JKHoehne/SVoice: First release of SVoice,2021-03-29,This is the initial release,"JKHoehne, Konstantin Gavras",software,other-open,https://zenodo.org/records/4644590
10.5281/zenodo.1117228,RUSSE'2018: Human-Annotated Sense-Disambiguated Word Contexts for Russian,2018-01-31,"This dataset contains human-annotated sense identifiers for 2562 contexts of 20 words used in the <a href=""https://russe.nlpub.org/2018/wsi/"">RUSSE&#39;2018</a> shared task on Word Sense Induction and Disambiguation for the Russian language; part of the&nbsp;<em>bts-rnc</em>&nbsp;evaluation dataset. These sense identifiers are disambiguated as according to the sense inventory of the <a href=""http://gramota.ru/slovari/info/bts/"">Large Explanatory Dictionary of Russian</a>.  The annotation is done on December 1, 2017, on the&nbsp;<a href=""https://tolokanyandex.com/"">Yandex.Toloka</a>&nbsp;crowdsourcing platform. In particular, 80 pre-annotated contexts are used for&nbsp;training the human annotators, 2562 contexts are annotated by humans such that each&nbsp;context was annotated by 9 different annotators. The annotation reliability&nbsp;is indicated by a high value of Krippendorff&#39;s&nbsp;&alpha; = 0.83. After the annotation, every context was additionally inspected (&ldquo;curated&rdquo;) by the organizers of the shared task.  The following words are represented:&nbsp;<em>акция</em> (action / stock), <em>байка</em> (yarn / tale), <em>гвоздика</em> (carnation / nail), <em>гипербола</em> (hyperbole), <em>град</em> (avalanche), <em>гусеница</em> (grub), <em>домино</em> (domino), <em>кабачок</em> (marrow / pub), <em>капот</em> (hood), <em>карьер</em> (mine / career), <em>кок</em> (cook), <em>крона</em> (top / crown), <em>круп</em> (croup), <em>мандарин</em> (mandarine), <em>рок</em> (fate / rock), <em>слог</em> (syllable), <em>стопка</em> (glass, stack), <em>таз</em> (bowl), <em>такса</em> (rate / badger-dog), <em>шах</em> (shah / check).  The following files are included in this dataset:  <ul> 	<li>Toloka assignments (training:&nbsp;<em>tasks-train.tsv</em>, annotation: <em>tasks-test.tsv</em>)</li> 	<li>Toloka output (non-aggregated: <em>assignments_01-12-2017.tsv.xz</em>, aggregated:&nbsp;<em>aggregated_results_pool_1036853__2017_12_01.tsv</em>)</li> 	<li>annotator agreement report (<em>agreement.txt</em>)</li> 	<li>curated report (<em>report-curated.tsv.xz</em> and a supplementary file&nbsp;<em>tasks-eval.tsv.xz</em>)</li> 	<li>the final aggregated dataset (<em>bts-rnc-crowd.tsv</em>)</li> </ul>  The <em>bts-rnc-crowd.tsv</em>&nbsp;file has the following format: <em>id</em>, <em>lemma</em>, <em>sense_id</em>, <em>left</em> hand side context, <em>word</em> form, <em>right</em> hand side context, list of&nbsp;<em>senses</em>. The encoding is UTF-8 and the line breaks are LF (UNIX).","Ustalov, Dmitry",dataset,cc-by-sa-4.0,https://zenodo.org/records/1117228
10.5281/zenodo.3899860,chainsawriot/gitforbartenders: es,2020-06-18,Git for Bartenders.,Chung-hong Chan,software,other-open,https://zenodo.org/records/3899860
10.5281/zenodo.3905332,chainsawriot/cj-find: cj-find,2020-06-23,Finding Chang-jie of Traditional Chinese words,Chung-hong Chan,software,other-open,https://zenodo.org/records/3905332
10.5281/zenodo.10405073,"KG-enricher: An open-source Python library for enriching strings, entities and knowledge graphs using Wikibase knowledge graphs",2023-12-19,"KG-enricher is an open-source Python library for enriching strings, entities and knowledge graphs using Wikibase knowledge graphs. It's adapted for people, organizations and German geographic entities, both modern and historical.","Shigapov, Renat",software,cc-by-4.0,https://zenodo.org/records/10405073
10.5281/zenodo.3904902,chainsawriot/coolcocktails: Cool Cocktails,2020-06-23,No description provided.,Chung-hong Chan,software,other-open,https://zenodo.org/records/3904902
10.5281/zenodo.4016596,chainsawriot/baaugwo: rjournal version,2020-09-06,R Package archiver.,Chung-hong Chan,software,other-open,https://zenodo.org/records/4016596
10.5061/dryad.j3tx95x8x,Stratified Reward Structures and Competition in Markets for Creative Production,2019-12-12,"Stratified reward structures have emerged as a universal feature of modern society, but their implications on the producers and consumers of creative work are not fully understood. We conducted an online experiment to test the effects of reward stratification in peer-reviewed creative production markets. We find that competition induced by stratification shapes the evolution of creative production, and that the quality of each tier in a stratified market is consistent with its position in the hierarchy. The top tier maintains high-quality standards by attracting many submissions and by filtering its output, operating as an effective sorting device for budget-constrained consumers. However, stratification generates higher levels of inequality among producers, leading to higher rates of market-exit for those lagging behind. We discuss the broad implications of reward stratification and artificial scarcity in hypercompetitive environments, contributing to the debate on cumulative advantage and the allocation of funding and recognition in science.","Balietti, Stefano, Riedl, Christoph",dataset,cc-zero,https://zenodo.org/records/5013517
10.5281/zenodo.1067701,"Polidoc.net CODEBOOK: National and Regional Manifestos and other Political Documents Collected for the Research Projects ""Representation in Europe: Congruence  between Preferences of Elites and Voters"" (REPCONG) and ""The Impact of EU Cohesion Policy on European Identification"" (COHESIFY)",2017-11-21,"The Political Documents Archive http://www.polidoc.net/&nbsp;contains election manifestos, coalition agreements, government declarations and various other documents of political actors from developed democracies. Currently, the archive builds on a stock of more than 3000 political documents from 20 European countries. The aim of the repository is to provide political texts in order to facilitate scholarly research in different areas of comparative politics such as party competition, coalition politics, legislative decision-making or electoral behavior.  National electoral manifestos have been collected in the course of the REPCONG project (&quot;Representation in Europe: Policy Congruence between Citizens and Elites&quot;), and the archive includes party manifestos for regional elections in several European democracies. Because the process of European integration resulted in a strengthening of regions in EU member states and in countries that want to join the European Union, the relevance of the regional level for political decision-making has increased during the last decades. Therefore, also the policy profiles of regional parties are required to get a full picture of democratic responsiveness in European states across all levels of the political system. The collection of regional manifestos was supported by the COHESIFY project (www.cohesify.eu), funded under the Horizon 2020 Framework Programme for Research and Innovation. The aim of COHESIFY is to study whether the European Structural and Investment Funds affect people&rsquo;s support for and identification with the European project.  The archive is freely accessible (after a simple registration) and meant to foster rigorous research in these areas by enabling scholars to produce valid and reliable findings from empirical studies of textual data rather than unnecessarily struggling to obtain and process texts.","Bräuninger, Thomas, Debus, Marc, Benoit, Kenneth, Bernauer, Julian, Polidoc.net Team",dataset,cc-by-4.0,https://zenodo.org/records/1067701
10.5281/zenodo.2583247,"DOI-to-DOI citations of articles '10.12685/027.7-4-2-155', '10.18452/9093' and '10.11588/PB.2012.1.9398'",2019-03-04,"This data set contains the references to publications with a DOI from my publications:  <ul> 	<li>Baierer, Konstantin ; Zumstein, Philipp (2016): Verbesserung der OCR in digitalen Sammlungen von Bibliotheken. <em>027.7 : Zeitschrift f&uuml;r Bibliothekskultur = Journal for Library Culture</em>, 4(2):72-83. <a href=""https://doi.org/10.12685/027.7-4-2-155"">https://doi.org/10.12685/027.7-4-2-155</a></li> 	<li>Kim, Timotheus Chang-whae ; Zumstein, Philipp (2016): Semiautomatische Katalogisierung und Normdatenverkn&uuml;pfung mit Zotero im Index Theologicus. <em>LIBREAS. Library ideas,</em> [12]:29 47-56. <a href=""https://doi.org/10.18452/9093"">https://doi.org/10.18452/9093</a></li> 	<li>Zumstein, Philipp (2012): Die Rolle des Semantic Web f&uuml;r Bibliotheken: Linked Open Data und mehr: Welche Strategien k&ouml;nnen hier die Bibliotheken in die Zukunft f&uuml;hren? <em>Perspektive Bibliothek ,</em> 1(1):81-102. <a href=""https://doi.org/10.11588/PB.2012.1.9398"">https://doi.org/10.11588/PB.2012.1.9398</a></li> </ul>",Philipp Zumstein,dataset,cc-zero,https://zenodo.org/records/2583247
10.5281/zenodo.11348256,Energy Tax Exemptions and Industrial Production,2024-05-27,"<div> <div> <div> The code in this replication package constructs the files used to produce the results in Lamp and Gerster (2024) ""Energy Tax Exemptions and Industrial Production"". All results were generated using STATA. As the main data are confidential and can only be accessed through the research centres of the Statistical Offices in Germany (see README for details), this replication package includes simulated data to run the code and obtain all tables and figures. </div> </div> </div>","Gerster, Andreas, Lamp, Stefan",software,cc-by-4.0,https://zenodo.org/records/11348256
10.5281/zenodo.6940608,"Replication package for ""The Central Bank Strikes Back! Credibility of Monetary Policy under Fiscal Influence""",2022-07-29,This replication package accompanies Camous A. and D. Matveev. &quot;The Central Bank Strikes Back! Credibility of Monetary Policy under Fiscal Influence&quot;.<br> &nbsp;,"Antoine Camous, Dmitry Matveev",software,cc-by-4.0,https://zenodo.org/records/6940608
10.5281/zenodo.13325994,"Replication Artifact Towards Deep Reactions in Multi-Level, Multi-View Modeling",2024-08-15,"Replication Artifact for the paper Towards Deep Reactions in Multi-Level, Multi-View Modeling published at the MULTI workshop at MODELS 2024 in Linz. This artifact contains the prototypical integration of Melanee models into Vitruvius we presented in the paper. See the README for more information.","Weber, Thomas, Lange, Arne",software,cc-by-4.0,https://zenodo.org/records/13325994
10.5281/zenodo.10829905,Overview of the SV-Ident 2022 Shared Task on Survey Variable Identification in Social Science Publications,2024-03-18,"This release includes the data and code associated with the <a href=""https://aclanthology.org/2022.sdp-1.29.pdf"">Overview of the SV-Ident 2022 Shared Task on Survey Variable Identification in Social Science Publications</a> paper.","Tsereteli, Tornike, Kartal, Yavuz Selim, Ponzetto, Simone Paolo, Zielinski, Andrea, Eckert, Kai, Mayr, Philipp",software,cc-by-4.0,https://zenodo.org/records/10829905
10.5281/zenodo.8171106,m2aia/mitk-elastix: v2023.08,2023-07-21,This is a MITK extension that provides utilities and plugins for image-based registration using the Elastix registration framework.,Jonas Cordes,software,other-open,https://zenodo.org/records/8171106
10.5281/zenodo.10213835,m2aia/pym2aia: 0.5.10,2023-11-28,pyM²aia is a Python package for memory-efficient access and processing of mass spectrometry image data. The I/O functionality is derived from the interactive desktop application M²aia. Special features are the batch generator utilities for deep learning applications.,Jonas Cordes,software,cc-by-4.0,https://zenodo.org/records/10213835
10.5281/zenodo.13952579,MimIR: An Extensible and Type-Safe Intermediate Representation for the DSL Age,2024-10-15,"Traditional compilers, designed for optimizing low-level code, fall short when dealing with modern, computation-heavy applications like image processing, machine learning, or numerical simulations.<br>Optimizations should understand the primitive operations of the specific application domain and thus happen on that level. Domain-specific languages (DSLs) fulfill these requirements.<br>However, DSL compilers reinvent the wheel over and over again as standard optimizations, code generators, and general infrastructure &amp; boilerplate code must be reimplemented for each DSL compiler. This paper presents MimIR, an extensible, higher-order intermediate representation.<br>At its core, MimIR is a pure type system and, hence, a form of a typed lambda calculus.<br>Developers can declare the signatures of new (domain-specific) operations, called <em>axioms</em>.<br>An axiom can be the declaration of a function, a type constructor, or any other entity with a possibly polymorphic, polytypic, and/or dependent type.<br>This way, developers can extend MimIR at any low or high level and bundle them in a <em>plugin</em>.<br>Plugins extend the compiler and take care of optimizing and lowering the plugins' axioms. We show the expressiveness and effectiveness of&nbsp;MimIR in three case studies:<br>Low-level plugins that operate at the same level of abstraction as LLVM, a regular-expression matching plugin, and plugins for linear algebra and automatic differentiation.<br>We show that in all three studies,&nbsp;MimIR produces code that has state-of-the-art performance. The artifact consists of:<br>* 3 benchmarks<br>* 1 Coq proof Everything is provided in a bundled VirtualBox image. The sources for the artifact are available at the <a href=""https://github.com/AnyDSL/popl25"" target=""_blank"" rel=""noopener"">GitHub repo</a> which contains submodules with all dependencies. Please refer to the ReadMe in our repo for the currently up-to-date notes on running the artifact: https://github.com/AnyDSL/popl25/blob/master/README.md","Leißa, Roland, Ullrich, Marcel, Meyer, Joachim, Hack, Sebastian",software,mit-license,https://zenodo.org/records/13952579
10.5281/zenodo.8171111,m2aia/mitk-docker: v2023.08,2023-07-21,This project provides utilities to run Docker commands from within MITK and Docker based processing views.,Jonas Cordes,software,other-open,https://zenodo.org/records/8171111
10.5281/zenodo.10581515,m2aia/m2aia: v2024.01,2024-01-29,"<h2>Changelog</h2> <ul> <li>Vector data as nodes Centroid lists and overview spectra</li> <li>Export/import of vector data as centroid lists</li> <li>Update default Perspective</li> <li>Stability improvments of all kinds</li> <li>Docker based processing views:<ul> <li>Dimensionality reduction <a href=""https://umap-learn.readthedocs.io/en/latest/"">UMAP</a></li> <li><a href=""https://www.nature.com/articles/s41467-021-25744-8"">PeakLearning</a></li> <li><a href=""https://github.com/CeMOS-Mannheim/moleculaR"">MoleculaR</a></li> </ul> </li> </ul> <h2>Structural changes</h2> <ul> <li>M2aia's I/O utilities can now be use in python (https://github.com/m2aia/pym2aia)</li> <li>Start docker containers from within MITK using mitk-docker (https://github.com/m2aia/mitk-docker)<ul> <li>Note: this works only with native installations of M2aia (and not in the browser)</li> </ul> </li> <li>Image registration is now a MITK extension (https://github.com/m2aia/mitk-elastix)</li> </ul> <h2>What's Changed</h2> <strong>Full Changelog</strong>: https://github.com/m2aia/m2aia/compare/v2022.08.00...v2024.01",Jonas Cordes,software,cc-by-4.0,https://zenodo.org/records/10581515
10.5281/zenodo.11112270,m2aia/m2aia-docker: v2024.05,2024-05-04,The first release of a set of container used for remote access to image data.,Jonas Cordes,software,cc-by-4.0,https://zenodo.org/records/11112270
10.5281/zenodo.14800284,zewwwwEcon,2025-02-06,"The <code>zewwwwEcon</code> package allows to start a new project in <a href=""https://posit.co/download/rstudio-desktop/"" rel=""nofollow"">RStudio</a> that contains the basic setup for an empirical research project. It features <a href=""https://quarto.org/"" rel=""nofollow"">Quarto</a> templates and some <code>ggplot2</code> style adjustments to generate nice looking PDFs for Slides and Paper in an environment that makes reproducibility easy.","Reif, Simon, Stelter, Benedikt",software,mit-license,https://zenodo.org/records/14800284
10.5281/zenodo.13852642,VisualTorch: Streamlining Visualization for PyTorch Neural Network Architectures,2024-09-28,"VisualTorch is a library designed for visualizing neural network architectures in PyTorch. It offers support for multiple visualization styles, such as layered-style, graph-style, and the newly added LeNet-like visualization. When provided with a sequential or custom PyTorch model, alongside the input shape and visualization specifications, VisualTorch automatically translates the model structure into an architectural diagram. The resulting diagram can be refined using various configurations, including style, color, opacity, size, and a legend. VisualTorch is particularly valuable for projects involving PyTorch-based neural networks. By facilitating the generation of graphics with a single function call, it streamlines the process of visualizing neural network architectures. This ensures that the produced results are suitable for publication with minimal additional modifications. Moreover, owing to its diverse customization options, VisualTorch empowers users to generate polished figures suitable for publication.","Hendria, Willy Fitra, Gavrikov, Paul",software,mit-license,https://zenodo.org/records/13852642
10.5281/zenodo.14898687,"Replication package ""Unemployment insurance reforms and labor market dynamics""",2025-02-20,"These files provide the replication code and data for the paper ""Unemployment insurance reforms and labor market dynamics"" by Benjamin Hartung, Philip Jung, and Moritz Kuhn","Hartung, Benjamin, Jung, Philip, Kuhn, Moritz",software,cc-by-4.0,https://zenodo.org/records/14898687
10.5281/zenodo.4026589,chainsawriot/rstyle: rjournal version,2020-09-12,The version of all code and data (as of the 2nd R Journal submission.),"Chung-hong Chan, Chiayi Yen, Mia // Huai-Wen Chang",software,other-open,https://zenodo.org/records/4026589
10.5281/zenodo.15224731,Knowledge Graph Functions in NFDI,2025-04-15,"The dataset contains use case examples from Knowledge Graph (KG) projects across the NFDI consortia, including the KG names, as well as the challenges the consortia faced in the process of employing a KG for the consortium. Lastly, the functions supported by the KGs are organized according to several categories.","Shigapov, Renat, Schubotz, Moritz, Fliegl, Heike, Norouzi, Ebrahim, Fortmann-Grote, Carsten, Becker, Markus, Rossenova, Lozana, Tietz, Tabea, Posthumus, Etienne, Zapilko, Benjamin, Dietze, Stefan, Gesese, Genet-Asefa, Degbelo, Auriol, Grieb, Jonas, Rebecca Ondraszek, Sarah, Voss, Jakob, Thiery, Florian, W. Mees, Allard, Goedicke, Michael, Kaplan, Angelika, Limani, Fidan",dataset,cc-by-4.0,https://zenodo.org/records/15224731
10.5281/zenodo.6798690,paulcbauer/apis_for_social_scientists_a_review: v1.0,2022-07-05,"What's Changed <ul> <li>Add a chapter on best practices by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/2"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/2</a></li> <li>Correct link and some typos in the Best Practices chapter by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/4"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/4</a></li> <li>Add Twitter chapter by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/5"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/5</a></li> <li>Fix the footnotes with non-numerical references by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/7"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/7</a></li> <li>Add chapter on FB Ads Library API by @opop999 in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/8"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/8</a></li> <li>Add a chapter on Media Cloud by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/11"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/11</a></li> <li>genderize.io API chapter by @internaut in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/12"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/12</a></li> <li>Modify Facebook Ads chapter with cached dataset by @opop999 in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/16"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/16</a></li> <li>Test by @dlajic in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/17"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/17</a></li> <li>Revert ""Test"" by @clandesv in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/18"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/18</a></li> <li>Überarbeitungen Kapitel (#19) by @clandesv in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/20"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/20</a></li> <li>References for google news API chapter by @BernhardClemm in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/22"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/22</a></li> <li>Google News API chapter - datasets by @BernhardClemm in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/23"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/23</a></li> <li>Google News API - RMD upload by @BernhardClemm in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/24"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/24</a></li> <li>GitHub API chapter by @internaut in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/25"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/25</a></li> <li>Minor fixes by @internaut in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/26"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/26</a></li> <li>Genderize.io / GitHub API - small fixes by @internaut in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/27"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/27</a></li> <li>Hide the details about caching in the Google news Chapter by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/28"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/28</a></li> <li>Fix #31 by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/33"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/33</a></li> <li>Make <code>introduction</code> also use <code>.gen_pacman_chunk()</code> by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/32"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/32</a></li> <li>Remove <code>.DS_Store</code> and put common rubbish into <code>.gitignore</code> by @chainsawriot in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/34"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/34</a></li> <li>Submit chapter Internet Archive API and archiveRetriever by @liserman in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/35"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/35</a></li> </ul> New Contributors <ul> <li>@chainsawriot made their first contribution in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/2"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/2</a></li> <li>@opop999 made their first contribution in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/8"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/8</a></li> <li>@internaut made their first contribution in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/12"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/12</a></li> <li>@clandesv made their first contribution in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/18"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/18</a></li> <li>@BernhardClemm made their first contribution in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/22"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/22</a></li> <li>@liserman made their first contribution in <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/35"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/pull/35</a></li> </ul> <strong>Full Changelog</strong>: <a href=""https://github.com/paulcbauer/apis_for_social_scientists_a_review/commits/v1.0"">https://github.com/paulcbauer/apis_for_social_scientists_a_review/commits/v1.0</a>","Paul C. Bauer, Camille Landesvatter, Lion Behrens, Markus Konrad, Chung-hong Chan, Ondrej Pekacek, dlajic, BernhardClemm, KaMaPh, Pirmin Stöckle, Lukas Isermann",software,other-open,https://zenodo.org/records/6798690
10.5281/zenodo.6395308,patccat: A classifier for patent claims,2022-03-31,"<strong>Data version: 3.3.0</strong> Authors:<br>Bernhard Ganglmair (University of Mannheim, Department of Economics, and ZEW Mannheim)<br>W. Keith Robinson (Wake Forest University, School of Law)<br>Michael Seeligson (Southern Methodist University, Cox School of Business) <br>1. Notes on Data Construction<br>2. Citation and Code<br>3. Description of the Data Files<br>3.1. File List<br>3.2. List of Variables for Files with Claim-Level Information<br>3.3. List of Variables for Files with Patent-Level Information<br>4. Coming Soon! <br><strong>1. Notes on Data Construction</strong> This is version 3.3.0 of the patccat data (patent claim classification by algorithmic text analysis). Patent claims define an invention. A patent application is required to have one or more claims that distinctly claim the subject matter which the patent applicant regards as her invention or discovery. We construct a classifier of patent claims that identifies three distinct claim types: process claims, product claims, and product-by-process claims. For this classification, we combine information obtained from both the preamble and the body of a claim. The preamble is a general description of the invention (e.g., a method, an apparatus, or a device), whereas the body identifies steps and elements (specifying in detail the invention laid out in the preamble) that the applicant is claiming as the invention. The combination of the preamble type and the body type provides us with a more detailed and more accurate classification of claims than other approaches in the literature. This approach also accounts for unconventional drafting approaches. We eventually validate our classification using close to 10,000 manually classified claims. The data files contain the results of our classification. We provide claim-level information for each independent claim of U.S. utility patents granted between 1836 and 2020. We also provide patent-level information, i.e., the counts of different claim types for a given patent. For a detailed description of our classification approach, please take a look at the accompanying paper (Ganglmair, Robinson, and Seeligson 2022). <strong>2. Citation</strong> Please cite the following paper when using the data in your own work: Ganglmair, Bernhard, W. Keith Robinson, and Michael Seeligson (2022): ""The Rise of Process Claims: Evidence from a Century of U.S. Patents,"" unpublished manuscript available at <a href=""https://papers.ssrn.com/abstract=4069994"">https://papers.ssrn.com/abstract=4069994</a>. In the paper, we document the use of process claims in the U.S. over the last century, using the patccat data. We show an increase in the annual share of process claims of about 25 percentage points (from below 10% in 1920). This rise in process intensity of patents is not limited to a few patent classes, but we observe it across a broad spectrum of technologies. Process intensity varies by applicant type: companies file more process-intense patents than individuals, and U.S. applicants file more process-intense patents than foreign applicants. We further show that patents with higher process intensity are more valuable but are not necessarily cited more often. Last, process claims are on average shorter than product claims (with the gap narrowing since the 1970s). We would love to see how other researchers use the data and eventually learn from it. If you have a discussion paper or a publication in which you use the data, please send us a copy at patccat.data@gmail.com. We will the R code used to construct the data on Github with the next data version (version 3.4.0). Contact us at b.ganglmair@gmail.com if you would like to take a look at an earlier version of the code. <br><strong>3. Description of the Data Files</strong> The data files contain claim-level information for independent claims of 10,140,848 U.S. utility patents granted between 1836 and 2020. The files further contain patent-level information for U.S. utility patents. <em>3.1. File List</em> File list <table><tbody> <tr> <td>claims-patccat-v3-3-sample.csv</td> <td>claim-level information for independent claims of a sample of 1000 patents issued between 1976 and 2020</td> </tr> <tr> <td>claims-patccat-v3-3-1836-1919.csv</td> <td>claim-level information for independent claims of 1,038,041 patents issued between 1836 and 1919</td> </tr> <tr> <td>claims-patccat-v3-3-1920-2020.csv</td> <td>claim-level information for independent claims of 9,102,807 patents issued between 1920 and 2020</td> </tr> <tr> <td>patents-patccat-v3-3-sample.csv</td> <td>patent-level information for a sample of 1000 patents issued between 1976 and 2020</td> </tr> <tr> <td>patents-patccat-v3-3-1836-1919.csv</td> <td>patent-level information for 1,038,041 patents issued between 1836 and 1919</td> </tr> <tr> <td>patents-patccat-v3-3-1920-2020.csv</td> <td>patent-level information for 9,102,807 patents issued between 1920 and 2020</td> </tr> </tbody> </table> <br><em>3.2. List of Variables for Files with Claim-Level Information</em> For detailed descriptions, see the appendix in Ganglmair, Robinson, and Seeligson (2022). List of Variables (Claim-Level Information) <table><tbody> <tr> <td>PatentClaim</td> <td>patent claim identifier; 8-digit patent number and 4-digit claim number (Ex: 01234567-0001)</td> </tr> <tr> <td>singleLine</td> <td>=1 if claim is published in single-line format</td> </tr> <tr> <td>singleReformat</td> <td>outcome code of reformating of single-line claims</td> </tr> <tr> <td>Jepson</td> <td>=1 if claim is a Jepson claim</td> </tr> <tr> <td>JepsonReformat</td> <td>outcome code of reformating of Jepson claims</td> </tr> <tr> <td>inBegin</td> <td>=1 if claim begins with the word ""in""</td> </tr> <tr> <td>wordsPreamble</td> <td>number of words in the claim preamble</td> </tr> <tr> <td>wordsBody</td> <td>number of words in the claim body</td> </tr> <tr> <td>dependentClaims</td> <td>number of dependent claims that refer to this independent claim</td> </tr> <tr> <td>isMeansPreamble</td> <td>=1 if term ""means"" is used in the preamble</td> </tr> <tr> <td>isMeansBody</td> <td>=1 if term ""means"" is used in the body</td> </tr> <tr> <td>isMeans</td> <td>=1 if term ""means"" is used anywhere in the claim (~ means-plus-function claim)</td> </tr> <tr> <td>processPreamble</td> <td>=1 if terms ""method"" or ""process"" are used in the preamble</td> </tr> <tr> <td>processBody</td> <td>=1 if terms ""method"" or ""process"" are used in the body</td> </tr> <tr> <td>processSimple</td> <td>=1 if terms ""method"" or ""process"" are used anywhere in the claim (for simple approach of process claim classification)</td> </tr> <tr> <td>claimType</td> <td>claim type of full classification (1 = process; 2 = product; 3 = product-by-process; 0 = no type)</td> </tr> <tr> <td>preambleType</td> <td>preamble type</td> </tr> <tr> <td>preambleTerm</td> <td>keyword used to classify preamble type</td> </tr> <tr> <td>preambleTermAlt</td> <td>alternative keyword (if preambleTerm were not used)</td> </tr> <tr> <td>preambleTextStub</td> <td>first 15 words of the preamble</td> </tr> <tr> <td>bodyType</td> <td>body type</td> </tr> <tr> <td>bodyLinesStep</td> <td>number of steps in the body</td> </tr> <tr> <td>bodyLinesElement</td> <td>number of elements in the body</td> </tr> <tr> <td>bodyLinesTotal</td> <td>total number of identified lines in the body</td> </tr> <tr> <td>label</td> <td>2-character label of the preamble-body combination; classification table maps label to claim type</td> </tr> </tbody> </table> &nbsp; <em>3.3. List of Variables for Files with Patent-Level Information</em> For detailed descriptions, see the appendix in Ganglmair, Robinson, and Seeligson (2022). List of Variables (Patent-Level Information) <table><tbody> <tr> <td>patent_id</td> <td>U.S. patent number (8-digit patent number)</td> </tr> <tr> <td>claims</td> <td>number of independent claims (the sum of the four claim types: 0, 1, 2, and 3)</td> </tr> <tr> <td>noCategory</td> <td>number of claims without a classified type</td> </tr> <tr> <td>processClaims</td> <td>number of process claims</td> </tr> <tr> <td>productClaims</td> <td>number of product claims</td> </tr> <tr> <td>prodByProcessClaims</td> <td>number of product-by-process claims</td> </tr> <tr> <td>firstClaim</td> <td>type of the first claim (1 = process; 2 = product; 3 = product-by-process; 0 = no type)</td> </tr> <tr> <td>simpleProcessClaims</td> <td>number of process claims by simple approach (terms ""method"" or ""process"" anywhere in the claim)</td> </tr> <tr> <td>simpleProcessPreamble</td> <td>number of process claims by simple approach (terms ""method"" or ""process"" in the preamble)</td> </tr> <tr> <td>meansClaims</td> <td>number of means-plus-function claims</td> </tr> <tr> <td>meansFirst</td> <td>=1 if first claim is a means-plus-function claim</td> </tr> <tr> <td>JepsonClaims</td> <td>number of Jepson claims</td> </tr> <tr> <td>JepsonFirst</td> <td>=1 if first claim is a Jepson claim</td> </tr> </tbody> </table> <br>Note: The following variables/fields are currently empty (March 30, 2020); we will populate these variables/fields with data version 3.4.0. preambleTerm<br>preambleTermAlt<br>preambleTextStub<br>bodyLinesStep<br>bodyLinesElement<br>bodyLinesTotal Note: We will release the data for patents issued in 2021 with data version 3.4.0. <br><strong>4. Coming Soon!</strong> We are working on a number of extensions of the patccat data. - With data version 3.4.0, we plan to release data for all published U.S. patent applications (2001 through 2021)<br>- In late spring/early summer 2022, we will release data for patents issued by the European Patent Office (EPO) [<strong>Update: March 28, 2023</strong>: see <a href=""https://doi.org/10.5281/zenodo.7776092"">https://doi.org/10.5281/zenodo.7776092</a>]<br>- In late spring/early summer 2022, we will release data for patents issued by the Canadian Intellectual Property Office (CIPO) &nbsp;","Ganglmair, Bernhard, Robinson, W. Keith, Seeligson, Michael",dataset,cc-by-4.0,https://zenodo.org/records/6395308
10.5281/zenodo.7776093,The patccat classifier for patent claims - EPO edition,2023-03-27,"!!! This is the <strong>EPO/European version</strong> of the patccat classifier of patent claims. !!!  Note: We use the same approach that we use for USPTO patents. For a detailed description, see <a href=""https://doi.org/10.5281/zenodo.6395307"">https://doi.org/10.5281/zenodo.6395307</a>.  <strong>Data version: 3.4.0</strong>  Authors:<br> Bernhard Ganglmair (University of Mannheim, Department of Economics, and ZEW Mannheim)<br> W. Keith Robinson (Wake Forest University, School of Law)<br> Michael Seeligson (Southern Methodist University, Cox School of Business)  Please cite the following paper when using the data in your own work:  Ganglmair, Bernhard, W. Keith Robinson, and Michael Seeligson (2022): &quot;The Rise of Process Claims: Evidence from a Century of U.S. Patents,&quot; unpublished manuscript available at <a href=""https://papers.ssrn.com/abstract=4069994"">https://papers.ssrn.com/abstract=4069994</a>.","Ganglmair, Bernhard, Robinson, W. Keith, Seeligson, Michael",dataset,cc-by-4.0,https://zenodo.org/records/7776093
10.5281/zenodo.14500757,"Mandated Sick Pay: Coverage, Utilization, and Crowding-In Effects",2024-12-16,"This package contains the data, programs and instructions to replicate manuscript ""Mandated Sick Pay: Coverage, Utilization, and Crowding-In Effects"" by Maclean, Pichler, Ziebarth forthcoming at JEEA.","Pichler, Stefan, Maclean, Johanna Catherine, Ziebarth, Nicolas Robert",software,cc-by-4.0,https://zenodo.org/records/14500757
10.5281/zenodo.7341310,Interactive Widget – Acceptance of autonomous vehicles dataset exploration,2022-11-21,"<strong><a href=""https://research-data.shinyapps.io/CAV_Acceptance/"">https://research-data.shinyapps.io/CAV_Acceptance/</a></strong> The following widget gives citizens access to data collected with the Connected and Autonomous Vehicle Acceptance Assessment Tool (CAVA) developed in the PAsCAL project (Public acceptance of Connected and Autonomous vehicles). The aim of the CAVA is to measure autonomous vehicle acceptance via evaluation of expected autonomous vehicle consequences. A survey was employed with over 5000 participants from 11 countries.","Celina Kacperski, Tobias Vogel, Florian Kutzner",dataset,cc-by-4.0,https://zenodo.org/records/7341310
10.5281/zenodo.15398296,Beyond Edge Addition,2025-05-13,"<h1>Beyond Edge Addition: A Dataset for<br>Information Extraction Incorporating New<br>Instances, Types, and Relations</h1> Information extraction (IE) is the task of converting natural&nbsp;language text into structured triples comprising a subject, predicate, and&nbsp;object. Existing IE datasets often operate under the assumption that all&nbsp;entities (instances, properties, and classes) are already defined within a&nbsp;knowledge graph (KG), focusing solely on discovering the relationships&nbsp;between them. However, this assumption does not align with real-world&nbsp;scenarios, where many entities and relationships may be missing in the&nbsp;KG. Additionally, most current datasets do not provide a snapshot of the&nbsp;accompanying knowledge graph, leading to inconsistencies in evaluation,<br>as different systems may rely on different KG versions with varying degrees of completeness and labelling support. Such inconsistencies undermine fair benchmarking and reproducibility. In this paper, we introduce&nbsp;a novel information extraction dataset specifically designed to better&nbsp;reflect realistic KG incompleteness. Our dataset includes 20% missing&nbsp;classes and instances, along with 5% missing relations, requiring systems&nbsp;to not only add new links (edges) but also propose new instances, classes,<br>and relations. To ensure reproducibility and prevent leakage from pre-trained language models, we provide a heavily modified version of Wikidata where background knowledge cannot be exploited to trivially infer triples. This resource supports a more robust and comparable evaluation&nbsp;of IE systems in settings closer to real-world applications. We further&nbsp;present a strong baseline that employs large language models for extraction and disambiguation tasks, as well as encoder-based retrieval, to<br>integrate the background knowledge graph. It operates in several iterations, initially identifying a first set of triples, then progressively refining&nbsp;them by referencing the KG and generating new entities if necessary. &nbsp; <h1>Dataset Description</h1> There are two gzipped files uploaded. The first one contains the knowledge graph and the second one the actual dataset with the text and corresponding triples that should be extracted. The files are password protected such that the dataset is not easily included in future LLM training. The password can be found in the corresponding Github repository.","Hertling, Sven, Möller, Cedric, Mihindukulasooriya, Nandana, Usbeck, Ricardo",dataset,mit-license,https://zenodo.org/records/15398296
10.5281/zenodo.7707902,"Replication package for: ""Observed Patterns of Free-Floating Car-Sharing Use""",2024-04-15,"Replication packet for &ldquo;Observed Patterns of Free-Floating Car-Sharing Use.&rdquo; By Natalia Fabra, Catarina Pintassilgo, and Mateus Souza. SERIEs: Journal of the Spanish Economic Association.<br><br>The code in this replication packet generates all the tables and figures from the paper. The car-sharing trips data were obtained under confidentiality agreements thus cannot be publicly shared. To obtain permissions to access the car-sharing data, replicators may contact the authors. All other data are publicly available and included in the packet.","Natalia Fabra, Catarina Pintassilgo, Mateus Souza",dataset,cc-by-4.0,https://zenodo.org/records/7707902
10.5281/zenodo.5156518,mcboost: Multi-Calibration Boosting for R,2021-08-03,"Implements &#39;Multi-Calibration Boosting&#39; (2018) &lt;https://proceedings.mlr.press/v80/hebert-johnson18a.html&gt; and &#39;Multi-Accuracy Boosting&#39; (2019) &lt;arXiv:1805.12317&gt; for the multi-calibration of a machine learning model&#39;s prediction. &#39;MCBoost&#39; updates predictions for sub-groups in an iterative fashion in order to mitigate biases like poor calibration or large accuracy differences across subgroups. Multi-Calibration works best in scenarios where the underlying data &amp; labels are unbiased, but resulting models are. This is often the case, e.g. when an algorithm fits a majority population while ignoring or under-fitting minority populations.","Florian Pfisterer, Christoph Kern, Susanne Dandl, Mathew Sun, Michael P. Kim, Bernd Bischl",software,,https://zenodo.org/records/5156518
10.5281/zenodo.6119379,cjbarrie/academictwitteR: CRAN Release,2022-02-17,"<ul> <li>Added support for hydrating tweet ids (<code>hydrate_tweets</code>) [#260 Thanks Tim König]</li> <li>Added error capturing mechanism [#264 Thanks Tim König]</li> <li>Fixed a bug of <code>get_retweeted_by</code> [#287 Thanks Thomas Davidson]</li> <li>Various bug fixes [#273, #263, #267]</li> </ul>","Christopher Barrie, Justin Chun-ting Ho, Chung-hong Chan, Michael DeWitt, Tim König, Noelia Rico, Tom Davidson",software,other-open,https://zenodo.org/records/6119379
10.5281/zenodo.6226207,"Replication package for: ""Social class and (un)ethical behaviour: Causal and correlational evidence""",2022-02-22,Replication package for EJ article &quot;Social class and (un)ethical behaviour: Causal and correlational evidence&quot;,"Gsottbauer, Elisabeth, Müller, Daniel, Müller, Samuel, Trautmann, Stefan T., Zudenkova, Galina",software,cc-by-4.0,https://zenodo.org/records/6226207
10.5281/zenodo.7422629,Post-hypnotic suggestion improves confidence and speed of memory access with long-lasting effects,2022-07-18,"The attempt to improve memory has a long tradition. Previous studies do not provide clear evidence concerning the longevity of memory-improving effects which is crucial for clinical applications. In our study, we use the post-hypnotic suggestion of easy remembering to establish long-lasting effects, as post-hypnotic suggestions can be activated with a cue after the hypnotic state. We tested 24 highly suggestible participants in an online study. Participants learned word lists and recalled them later in a recognition memory task where both learned and new words were presented and participants rated their recognition confidence. At the beginning of the study, participants were hypnotized and the post-hypnotic suggestion to remember easily was associated with a cue that participants used during the recognition memory task in the easy-remembering condition. In a control condition, the same participants used a neutral cue. One week later, participants repeated both conditions with new word lists, relying on the same post-hypnotic suggestion they received the week before.  Participants were significantly faster and more confident in their recognition ratings in the easy-remembering condition compared to the control condition, and this effect persisted over one week. Crucially, the increased speed and confidence in the easy-remembering condition did not affect memory accuracy; numerically, participants were even slightly better at discriminating old from new words in the easy-remembering condition. These findings demonstrate that post-hypnotic suggestions of easy remembering improve recognition confidence and speed with long-lasting effects, which makes it a promising intervention for patients experiencing subjective memory impairments.  All experimental files to run the study in Gorilla are accessible via this link:&nbsp;https://app.gorilla.sc/openmaterials/430668","Barbara Schmidt, Justin Böhmer, Martin Schnürch, Tobias Koch, Sebastian Michelmann",dataset,cc-by-4.0,https://zenodo.org/records/7422629
10.5281/zenodo.7506459,Replication package for: How the Other Half Died: Immigration and Mortality in US Cities,2022-07-15,"The code in this replication package replicates *How the Other Half Died: Immigration and Mortality in US Cities*, RESTUD forthcoming. All code is in R. It first builds the analysis data from several raw data sources. It then produces all the figures and tables in the paper. One master file (`master.R`) runs all of the code to generate the input data and then the figures and tables in the paper (and then the figures and tables in the appendix).","Ager, Philipp, Feigenbaum, James, Hansen, Casper Worm, Tan, Hui Ren, Williamson, Danielle",dataset,cc-by-4.0,https://zenodo.org/records/7506459
10.5281/zenodo.14911157,Mannheim Privacy Policy Panel (MaPPP),2025-02-22,"<h3>1. Short Description</h3> The <strong>Mannheim Privacy Policy Panel (MaPPP)</strong> contains the texts of 1,775,388 million privacy policies posted by 311,539 German firms between 2012 and 2021. The files were collected from the Internet Archive via the Wayback Machine. The MaPPP is an unbalanced quarterly panel. For details on the data construction, consult the data appendix of the following paper: <em>Ganglmair, B., J. Kr&auml;mer, and J. Gambato. 2024. Regulatory Compliance with Limited Enforceability: Evidence from Privacy Policies. Unpublished manuscript, available at <a href=""https://ssrn.com/abstract=4600876"" target=""_blank"" rel=""noopener"">https://ssrn.com/abstract=4600876</a>.</em> <h3>2. Data Files</h3> The repository contains 40 RDA files (R data files) with quarterly observations from Q1 2012 through Q4 2021. Each RDA file contains a data frame ""<strong>mappp.policies</strong>"" with 6 variables. The unique identifier for a policy is a firm_ID-period combination. <table> <tbody> <tr> <td><strong>Variable</strong></td> <td><strong>Description</strong></td> <td><strong>Example</strong></td> </tr> <tr> <td>firm_ID</td> <td>firm identifier (crefo number; with suffix DE the same as the Orbis' BvDID</td> <td>2010000001</td> </tr> <tr> <td>period</td> <td>Quarter of the observation, in date format. January 1 (-01-01) is Q1; April 1 (-04-01) is Q2; July 1 (-07-01) is Q3; October 1 (-10-01) is Q4.</td> <td>2018-07-01</td> </tr> <tr> <td>date</td> <td>Date the policy was posted</td> <td>2018-08-31</td> </tr> <tr> <td>content</td> <td>Text of the privacy policy.</td> <td>(string)</td> </tr> <tr> <td>wordcount</td> <td>Simple word count</td> <td>2522</td> </tr> <tr> <td>URL</td> <td>URL of the privacy policy (not the Web Archive's address)</td> <td> <pre>http://wiener-conditorei.de/datenschutz/</pre> </td> </tr> </tbody> </table> <h3>3. Data Access</h3> Access is restricted. Contact Bernhard Ganglmair at b.ganglmair@gmail.com if you are interested in using the MaPPP for your research. <h3>4. Citation</h3> Cite the following paper when using the data: <em>Ganglmair, B., J. Kr&auml;mer, and J. Gambato. 2024. Regulatory Compliance with Limited Enforceability: Evidence from Privacy Policies. Unpublished manuscript, available at <a href=""https://ssrn.com/abstract=4600876"" target=""_blank"" rel=""noopener"">https://ssrn.com/abstract=4600876</a>.</em>","Ganglmair, Bernhard, Gambato, Jacopo, Krämer, Julia",dataset,cc-by-4.0,https://zenodo.org/records/14911157
10.5281/zenodo.14040310,"Replication package for ""Consumer Credit with Over-Optimistic Borrowers""",2024-11-05,"This package contains the data, programs and instructions to replicate manuscript ""Consumer Credit with Over-Optimistic Borrowers"" by Florian Exler, Igor Livshits, James MacGee, and Mich&egrave;le Tertilt forthcoming at JEEA.","Exler, Florian, Livshits, Igor, MacGee, James, Tertilt, Michele",software,cc-by-4.0,https://zenodo.org/records/14040310
10.5281/zenodo.10990452,"replication package for: ""Robot Imports and Firm-level Outcomes""",2024-04-18,"This is a replication package for the paper ""Robot Imports and Firm-level Outcomes"" by Alessandra Bonfiglioli, Rosario Crin&ograve;, Harald Fadinger and Gino Gancia. The package includes all the code and public data used to produce the figures and tables in the main text and appendices. The firm-level micro data and the data on the stock of installed robots by industry in the U.S. used in the paper are confidential and cannot be made publicly available.&nbsp;","Bonfiglioli, Alessandra, Crinò, Rosario, Fadinger, Harald, Gancia, Gino",software,cc-by-4.0,https://zenodo.org/records/10990452
10.5281/zenodo.4554112,Twenty-two Historical Encyclopedias Encoded in TEI: a New Resource for the Digital Humanities,2020-11-02,"Dataset described in &quot;Twenty-two Historical Encyclopedias Encoded in TEI: a New Resource for the Digital Humanities&quot;. These German encyclopedias have been uniformly annotated with a variant of TEI Lex-0. See the transformation code at <a href=""http://github.com/ThoraHagen/Encyc-Transformation"">GitHub</a>.  Licensed as CC-BY.","Hagen, Thora, Ketzan, Erik, Jannidis, Fotis, Witt, Andreas",dataset,cc-by-4.0,https://zenodo.org/records/4554112
10.5281/zenodo.7675783,Sources of PM2.5-associated Health Risks in Europe and Corresponding Emission-induced Changes during 2005-2015,2023-02-24,"-New data generated for 2022GH000767  -Including the&nbsp;calculated&nbsp;sensitivities of the total PM2.5-related premature deaths in Europe to anthropogenic&nbsp;emissions&nbsp;of SO2, NOx, NH3, OC, BC, and secondary organic aerosol precursors (SOAP) in 2015  -Including the simulated annual mean PM2.5 exposure and PM2.5-related premature death in 2015 from the base simulation&nbsp;and the sensitivity experiment in which all inputs of the boundary conditions were reduced by 20% (BC20), respectively.&nbsp;  -All the data were generated by the GEOS-Chem model and its adjoint","Yixuan Gu, Daven K. Henze, M. Omar Nawaz, Hansen Cao, Ulrich J. Wagner",dataset,cc-by-4.0,https://zenodo.org/records/7675783
10.5281/zenodo.5518208,"Replication package for: Killer Incentives: Rivalry, Performance and Risk-Taking among German Fighter Pilots, 1939-45",2021-09-21,"This package includes all the data and code necessary to reproduce the the figures and tables in Ager et al. (forthcoming).&nbsp;&quot;Killer Incentives: Rivalry, Performance and Risk-Taking among German Fighter Pilots, 1939-45.&quot; <em>Review of Economic Studies</em>.","Ager, Philipp, Bursztyn, Leonardo, Leucht, Lukas, Voth, Hans-Joachim",dataset,cc-by-4.0,https://zenodo.org/records/5518208
10.5281/zenodo.4159492,Twenty-two Historical Encyclopedias (Original XML Encoding),2020-11-02,This dataset accompanies the publication of &quot;Twenty-two Historical Encyclopedias Encoded in TEI: a New Resource for the Digital Humanities&quot;.  Licensed as CC-BY.,"Hagen, Thora, Ketzan, Erik, Jannidis, Fotis, Witt, Andreas",dataset,cc-by-4.0,https://zenodo.org/records/4159492
10.5281/zenodo.6327702,ClaudioZandonella/trackdown: v1.3.0,2022-03-04,"Introduce the <code>rich_text</code> feature and uses its own API credentials (see Issue #28) <ul> <li><strong><code>rich_text</code>.</strong> Upload <em>rich</em> documents to Google Docs where important text that should not be changed is automatically highlighted (e.g., placeholders hiding the code, header of the document, code chunks, and in-line code). See <a href=""https://claudiozandonella.github.io/trackdown/articles/trackdown-features.html#rich-text"">rich-text feature details</a>.</li> <li><strong>API Credentials.</strong> Now, <code>trackdown</code> uses its own Goole API credentials (OAuth client ID and secret). See details <a href=""https://claudiozandonella.github.io/trackdown/articles/trackdown-privacy-policy.html"">privacy policy</a>.</li> </ul>","Claudio Zandonella Callegher, Filippo Gambarota, Mathew Ling, Emily Kothe, Ben Marwick, Janosch Linkersdörfer, Chung-hong Chan",software,other-open,https://zenodo.org/records/6327702
10.5281/zenodo.4395092,Percutaneous transhepatic or endoscopic ultrasound-guided biliary drainage in malignant distal bile duct obstruction using a metal stent: study protocol for a prospective European multicentre trial (PUMa trial),2020-12-27,"<strong>Abstract:</strong>  <strong>Background</strong>  Percutaneous transhepatic biliary drainage [PTBD] is still universally used in patients with malignant distal bile duct obstruction when endoscopic retrograde cholangiopancreatography [ERCP] is not successful or not possible to perform. However, endoscopic ultrasound-guided biliary drainage [EUS-BD] was associated with better clinical success and a lower rate of adverse events (AE) in recent comparative studies, although further improvements in the PTBD technique, such as primary stent implantation as a one-step procedure, percutaneous ultrasound-guided bile duct puncture and left-sided bile duct access, were not considered. The aim of this study is to compare both procedures carried out as intended one-step procedures with primary metal stent insertion.  <strong>Methods</strong>  The PUMa trial is an ongoing European non-randomized, controlled, parallel group, non-inferiority multicentre trial. Fourteen study centres perform only one of the two procedures with regard to the best local experience. PTBD is performed as a one-step procedure with primary metal stent insertion after percutaneous ultrasound-guided bile duct access. EUS-BD is performed as a one-step procedure using the EUS-guided trans-gastric or trans-duodenal access route for trans-gastric trans-hepatic (EUS-HGS), trans-duodenal (EUS-CDS) or antegrade trans-papillary (EUS-AGS) metal stent insertion. The main target values are the technical and clinical success rates, AEs within 30 days and overall disease-specific survival within 6 months. The calculated total number of cases is 212 patients.  <strong>Discussion:</strong>  The PUMa trial investigates whether PTBD is not inferior to EUS-BD in terms of technical and clinical success if primary metal stent insertion is performed as a one-step procedure in both procedures. Differences are expected in the quantity and variety of AEs, number of re-interventions and length of hospital stay.  <strong>Trial Registration</strong>: ClinicalTrials.gov ID: NCT03546049 (date of registration 22.05.2018)","Daniel Schmitz, Carlos Tortosa Valiente",dataset,cc-by-4.0,https://zenodo.org/records/4395092
10.5281/zenodo.11180268,"Replication data for ""Learning When to Quit: An Empirical Model of Experimentation in Standards Development""",2024-05-28,"This is the replication data for the article ""Learning When To Quit: An Empirical Model of Experimentation in Standards Development,"" published in the <em>American Economic Journal: Microeconomics</em>.&nbsp; A detailed description of the data construction can be found in the Data Appendix (Section E in the Online Appendix published with the article's supplementary material). The file _readme-LWTQ-data.xls contains a description of the variables. If you use the data, cite the paper! <strong>Ganglmair, Bernhard, Timothy Simcoe, and Emanuele Taranntino (2024): ""Learning When To Quit: An Empirical Model of Experimentation in Standards Development,""&nbsp;<em>American Economic Journal: Microeconomics</em>, forthcoming<em>.</em></strong>","Ganglmair, Bernhard, Simcoe, Timothy, Tarantino, Emanuele",dataset,cc-by-nc-4.0,https://zenodo.org/records/11180268
10.5281/zenodo.7040492,Synthesis of large scale 3D microscopic images of 3D cell cultures for training and benchmarking,2023-02-24,Accompaning data to the paper:  Synthesis of large scale 3D microscopic images of 3D cell cultures for training and benchmarking,"Bruch, Roman, Keller, Florian, Böhland, Moritz, Vitacolonna, Mario, Klinger, Lukas, Rudolf, Rüdiger, Reischl, Markus",dataset,cc-by-4.0,https://zenodo.org/records/7040492
10.5061/dryad.02v6wwq50,Stress induced TDP-43 mobility loss independent of stress granules,2023-05-03,"TAR DNA binding protein 43 (TDP-43) is closely related to the pathogenesis of amyotrophic lateral sclerosis (ALS) and translocates to stress granules (SGs). The role of SGs as aggregation-promoting ""bioreactors"" for TDP-43, however, is still under debate. We analyzed TDP-43 mobility and localization under different stress and recovery conditions using live cell single-molecule tracking and super-resolution microscopy. Besides reduced mobility within SGs, a stress induced decrease of TDP-43 mobility in the cytoplasm and the nucleus was observed. Stress removal led to a recovery of TDP-43 mobility, which strongly depended on the stress duration. 'Stimulated-emission depletion microscopy' (STED) and 'tracking and localization microscopy' (TALM) revealed not only TDP-43 substructures within stress granules but also numerous patches of slow TDP-43 species throughout the cytoplasm. The data provide new insights into the aggregation of TDP-43 in living cells and provide evidence suggesting that TDP-43 oligomerization takes place in the cytoplasm separate from SGs.","Streit, Lisa, Kuhn, Timo, Vomhof, Thomas, Bopp, Verena, Ludolph, Albert C., Weishaupt, Jochen H., Gebhardt, J. Christof M., Michaelis, Jens, Danzer, Karin M.",dataset,cc-zero,https://zenodo.org/records/7893895
10.5281/zenodo.14960451,Measuring Rural and Urban Consciousness in Europe - Replication Materials,2025-03-03,"These data and code allow researchers to replicate the analyses in ""Measuring Rural and Urban Consciousness in Europe"", forthcoming in Electoral Studies, with authors:<br>Christopher Claassen, Sascha G&ouml;bel, Antonia Lang, Kathrin Ackermann, Petar Bankov, Kevin Brookes, Bartolomeo Cappellina, Christopher Carman, Markus Freitag, Rub&eacute;n Garc&iacute;a Del Horno, Enrique Hern&aacute;ndez, Guillem Rico, Sigrid Rossteutscher, Richard Traunm&uuml;ller, Michael Webb, Sonja Zmerli, and Alina Zumbrunn.","Claassen, Christopher, Göbel, Sascha, Ackermann, Kathrin, Lang, Antonia, Bankov, Petar, Brookes, Kevin, Cappellina, Bartolomeo, Freitag, Markus, García Del Horno, Rubén, Hernández, Enríque, Rico, Guillem, Rossteutscher, Sigrid, Traunmueller, Richard, Webb, Michael, Zmerli, Sonja, Zumbrunn, Alina",dataset,cc-by-4.0,https://zenodo.org/records/14960451
10.5281/zenodo.11587503,Data-Provenance-Initiative/Data-Provenance-Collection: Data Provenance Initiative Release,2024-06-11,Data Provenance Initiative initial release.,"shayne-longpre, Mohammed Hamdy, Ariel N. Lee, William Brannon, Manan Dey, Nayan Saxena, Yizhi Li, Minh Chien Vu, anmdinh, manandey-sfdx, Nikhil Singh, chkla, campbellslund, Lj Miranda, Kun Qian, Manuel Cherep, vipulgupta1011, Da Yin, Ahmad Mustafa Anis, DTM-ChienVM, Emad Alghamdi, minniemouse05, Niklas Muennighoff, Tobin South, lilloukas, sileod, DeividasAQ22, Xuhui Zhou, rmahari, Seungone Kim",software,cc-by-4.0,https://zenodo.org/records/11587503
10.5281/zenodo.3886884,epiTracker - A framework for highly-reliable particle tracking for the quantitative analysis of fish movements in tanks,2020-06-09,Algorithm for tracking of multiple fishes in recorded videos in combination with a semi automatic control and correction procedure to gain error free trajectories in an easy and quick manner.&nbsp;The integration into two graphical user interfaces ensures that also non specialists can use the software.,"Bruch Roman, Scheikl Paul M., Mikut Ralf, Loosli Felix, Reischl Markus",software,mit-license,https://zenodo.org/records/3886884
10.5281/zenodo.3885775,"Benchmark Data Set of ""epiTracker - A framework for highly-reliable particle tracking for the quantitative analysis of fish movements in tanks""",2020-06-09,"Data set containing five videos differing in fish species&nbsp;(zebrafish and medaka), number of individuals (3 to 10), lighting and type of tank for comparison of tracking algorithms. For each video a Matlab file (*.mat) exists, which contains the position data of the fish.  Each of the five&nbsp;videos consists of ~10000 frames, which at a frame rate of 30FPS corresponds to a length of about 5.5min.","Bruch Roman, Scheikl Paul M., Mikut Ralf, Loosli Felix, Reischl Markus",dataset,cc-by-4.0,https://zenodo.org/records/3885775
10.5281/zenodo.8187356,Towards substitution of invasive telemetry: An integrated home cage concept for unobtrusive monitoring of objective physiological parameters in rodents - Minimal dataset,2023-07-26,Minimal dataset &nbsp;for unobtrusive monitoring of vital parameters in rodents.,"Lucas Mösch, Janosch Kunczik, Lukas Breuer, Dorit Merhof, Peter Gass, Heidrun Potschka, Dietmar Zechner, Brigitte Vollmar, René Tolba, Christine Häger, André Bleich, Michael Czaplik, Carina Barbosa Pereira",dataset,cc-by-4.0,https://zenodo.org/records/8187356
10.5281/zenodo.8375191,Hepatitis D infection induces IFN-β-mediated NK cell activation and TRAIL-dependent cytotoxicity,2023-10-23,"The dataset contains bulk RNA-seq read count matrices of NK&nbsp;cells from healthy donors after 48 h of co-culture with hepatitis D virus infected and non-infected HepG2-hNTCP cells. The samples are described in the table&nbsp;RNA-seq_samples.xls that is included with the count matrices. Further details are given in the publication associated with this dataset (Groth et al., <i>Front Immunol</i>, 2023, https://doi.org/10.3389/fimmu.2023.1287367).","Christopher  Groth, Jovana Maric, Irene Garcés Lázaro, Tomáš Hofman, Zhenfeng Zhang, Yi Ni, Franziska Keller, Isabelle Seufert, Maike Hofmann, Christoph Neumann-Haefelin, Carsten Sticht, Karsten Rippe, Stephan Urban, Adelheid Cerwenka",dataset,cc-by-4.0,https://zenodo.org/records/8375191
10.5281/zenodo.14697221,nilearn,2025-01-20,"Nilearn enables approachable and versatile analyses of brain volumes. It provides statistical and machine-learning tools, with instructive documentation &amp; friendly community.","Nilearn contributors, Chamma, Ahmad, Frau-Pascual, Aina, Rothberg, Alex, Abadie, Alexandre, Abraham, Alexandre, Gramfort, Alexandre, Savio, Alexandre, Cionca, Alexandre, Sayal, Alexandre, Thual, Alexis, Kodibagkar, Alisha, Kanaan, Amadeus, Pinho, Ana Luisa, Joshi, Anand, Idrobo, Andrés Hoyos, Kieslinger, Anne-Sophie, Kumari, Anupriya, Rokem, Ariel, Mensch, Arthur, Vijayan, Aswin, Duran, Audrey, Cipollini, Ben, Thirion, Bertrand, Nguyen, Binh, Cakan, Caglar, Gorgolewski, Chris, Markiewicz, Chris, Horea, Christian, Gerloff, Christian, Roßmanith, Christina, Reininger, Colin, Lane, Connor, Sy, Czarina, Delettre, Céline, Gale, Dan, Gomez, Daniel, Bzdok, Danilo, Ellis, David G, Wassermann, Demian, Pisner, Derek, Orfanos, Dimitri Papadopoulos, DuPre, Elizabeth, Dohmatob, Elvis, Larson, Eric, Edmond, Evan, Pedregosa, Fabian, Pollet, Florent, Liem, Franz, Paugam, François, Varoquaux, Gael, Hollander, Gilles de, Kiar, Greg, Gilmore, Greydon, Lemaitre, Guillaume, Gözükan, Hande, Wang, Hao-Ting, Aggarwal, Himanshu, Abenes, Ian, Traore, Idrissa, Vogel, Jake, Margeta, Jan, Grobler, Jaques, Gors, Jason, Kai, Jason, Rasero, Javier, Kossaifi, Jean, King, Jean-Rémi, Dalenberg, Jelle Roelof, Lefort-Besnard, Jeremy, Dockes, Jerome, Chevalier, Jerome-Alexis, Wiesner, Johannes, Gorrono, Jon Haitz Legarreta, Sassenhagen, Jona, Huguet, Jordi, Teves, Joshua, Huntenburg, Julia, Peraza, Julio A, Daddy, Kamalakar Reddy, Sitek, Kevin, Helwegen, Koen, Wagstyl, Konrad, Shmelkov, Konstantin, Chawla, Kshitij, CHEN, Kun, Sasse, Leonard, Estève, Loic, Tetrel, Loic, Paz, Luz, Pietrantoni, Manon, Perez-Guevara, Martin, Wegrzyn, Martin, Goncalves, Mathias, Dugré, Mathieu, Ekman, Matthias, Joulot, Matthieu, Sitter, Maximilian Cosmo, Rahim, Mehdi, Zwally, Mia, Burkhardt, Micha, Eickenberg, Michael, Hanke, Michael, Notter, Michael, Waskom, Michael, Wang, Michelle, Torabi, Mohammad, Boos, Moritz, Chapra, Mudassir, Song, Myeong Seop, Clarke, Natasha, Shah, Neelay, Gensollen, Nicolas, Krish, Nikhil, Warrington, Oliver, Esteban, Oscar, Sadil, Patrick, Bogdan, Paul, Reiners, Paul, Sanz-Leon, Paula, Herholz, Peer, Gervais, Philippe, Bellec, Pierre, Glaser, Pierre, Quirion, Pierre-Olivier, Raamana, Pradeep Reddy, Jain, Prakhar, Brito, Rahul, Meudec, Raphael, Luke, Robert, Williamson, Robert, Guidotti, Roberto, Phlypo, Ronald, Hammonds, Ryan, Gau, Rémi, Patalasingh, Sachin, Hahn, Sage, Bougacha, Salma, Johnson, Sam Buck, Jawhar, Sami, Steinkamp, Simon, Kim, Sin, Singh, Sourav, Meisler, Steven, Pokharel, Suramya, Lan, Sylvain, Takerkart, Sylvain, Gezici, Tamer, Samanta, Tarun, Salo, Taylor, K, Tharun, Premrudeepreechacharn, Thiti, Bazeille, Thomas, Vanasse, Tom, Diogo, Vasco, Shevchenko, Victoria, Michel, Vincent, Fritsch, Virgile, Halchenko, Yaroslav, Mzayek, Yasmin, Huang, Yichun, Baratz, Zvi, Nájera, Óscar",software,bsd-4-clause,https://zenodo.org/records/14697221
10.5281/zenodo.5598010,Overview of preregistrations in the management and marketing fields,2021-10-25,"This dataset provides an overview of preregistrations that have been included in peer-reviewed articles (in leading journals)&nbsp;in the management, marketing, and information systems&nbsp;disciplines.  NB:  &#39;Experiment Count&#39; = Number of&nbsp;experiments&nbsp;in each case (incl. supplementary studies)  &#39;Preregistration Count&#39; = Number of preregistrations&nbsp;in each case  &#39;Publicly Available&#39; = Number of preregistrations that were retrievable at the point of publication of this analysis  &#39;Preregistration Ratio&#39; &nbsp;= Preregistration Count / Experiment Count (indicates how many studies were preregistered)  &#39;Institutional Affiliation by Region&#39; = Indicates whether an institution/region appears in the corresponding article (note that several appearances of one institution in a single article is not treated differently)","Eriksson, Oliver",dataset,cc-by-4.0,https://zenodo.org/records/5598010
10.5281/zenodo.13382927,Robust-Minisets,2024-08-29,"<h3>Abstract</h3> <div>We introduce <strong>Robust-Minisets</strong>, a collection of robust benchmark classification datasets in the low resolution realm based on well-established image classification benchmarks, such as CIFAR, Tiny ImageNet, EuroSAT and the MedMNIST collection. We port existing robustness and generalization benchmarks (ImageNet-C, -R, -A and v2) to the small dataset domain introducing novel benchmarks to comprehensively evaluate the robustness and generalization capabilities of image classification models on low resolution datsets. This results in an extensive collection consisting of already existing test sets (e.g. CIFAR-10.1 and Tiny ImageNet-C) as well as the novel benchmarks EuroSAT-C, MedMNIST-C, and Tiny ImageNet-A, -R and -v2 introduced in our ICPR 2024 paper&nbsp;<a href=""https://github.com/CeMOS-IS/GenFormer"">""GenFormer - Generated Images are All You Need to Improve Robustness of Transformers on Small Datasets""</a>.</div> <div>&nbsp;</div> <h3>Installation and Requirements</h3> <div> We recommend our official <a href=""https://github.com/CeMOS-IS/Robust-Minisets"">code</a> to download, parse and use the Robust-Minisets datasets: <blockquote> <pre>% pip install robust-minisets<br>% python</pre> <div> <div>To use a standard version utilizing the downloaded files:</div> <br> <div>&gt;&gt;&gt; from robust_minisets import TinyImageNetR</div> <div>&gt;&gt;&gt; test_dataset = TinyImageNetR(split=""test"")</div> <br> <div>To enable automatic downloading by setting `download=True`:</div> <br> <div>&gt;&gt;&gt; from robust_minisets import EuroSATC</div> <div>&gt;&gt;&gt; test_dataset = EuroSATC(split=""test"", download=True)</div> <br> <div>Additionally, we include training and validation datasets that are not provided in common hubs (e.g. torchvision):</div> <br> <div>&gt;&gt;&gt; from robust_minisets import EuroSAT</div> <div>&gt;&gt;&gt; train_dataset = EuroSAT(split=""train"", download=True)</div> <div>&gt;&gt;&gt; val_dataset = EuroSAT(split=""val"", download=True)</div> <div>&gt;&gt;&gt; test_dataset = EuroSAT(split=""test"", download=True)</div> </div> </blockquote> </div> &nbsp; <h3>License</h3> <div>The code is under <a href=""https://github.com/MedMNIST/MedMNIST/blob/main/LICENSE"">Apache-2.0 License</a>.</div> <div>&nbsp;</div> <div>The publication licenses of the datasets can be found within the info dictionary of our official code via <code>robust_minisets.INFO[&lt;dataset_flag&gt;]</code> or <a href=""https://github.com/CeMOS-IS/Robust-Minisets/blob/main/datasets.md"">here</a>.</div> &nbsp; <h3><strong>Citation</strong></h3> <div>If you find this work useful, please consider citing us:</div> <blockquote> <div>Sven Oehri, Nikolas Ebert, Ahmed Abdullah, Didier Stricker, Oliver Wasenm&uuml;ller. ""GenFormer - Generated Images are All You Need to Improve Robustness on Small Datasets"". International Conference on Pattern Recognition (ICPR), 2024.</div> </blockquote> <div>or using bibtex:</div> <blockquote>@inproceedings{oehri2024genformer,<br>&nbsp; &nbsp; title = {GenFormer &ndash; Generated Images are All You Need to Improve Robustness of Transformers on Small Datasets},<br>&nbsp; &nbsp; author = {Oehri, Sven and Ebert, Nikolas and Abdullah, Ahmed and Stricker, Didier and Wasenm{\""u}ller, Oliver},<br>&nbsp; &nbsp; booktitle = {International Conference on Pattern Recognition (ICPR)},<br>&nbsp; &nbsp; year = {2024},<br>}</blockquote> &nbsp; <div><strong>DISCLAIMER:</strong> Robust-Minisets is based on a wide range of existing datasets and benchmarks. Thus, please also cite source data paper(s) of the Robust-Minisets subset(s):</div> <div> <ul> <li><a href=""https://arxiv.org/abs/1806.00451"">CIFAR-10.1</a></li> <li><a href=""https://arxiv.org/abs/1709.00029"">EuroSAT</a></li> <li><a href=""https://arxiv.org/abs/1907.07174"">ImageNet-A</a></li> <li><a href=""https://arxiv.org/abs/1903.12261"">ImageNet-C</a></li> <li><a href=""https://arxiv.org/abs/2006.16241"">ImageNet-R</a></li> <li><a href=""https://arxiv.org/abs/1902.10811"">ImageNetv2</a></li> <li><a href=""https://www.nature.com/articles/s41597-022-01721-8"">MedMNIST</a>, the respective source datasets (described <a href=""https://medmnist.com/"">here)</a></li> </ul> </div> <div>&nbsp;</div> <h3>Release versions</h3> <div> <ul> <li>v1.0.0: Robust-Minisets v1 release</li> </ul> </div>","Oehri, Sven, Ebert, Nikolas, Abdullah, Ahmed, Stricker, Didier, Wasenmüller, Oliver",dataset,,https://zenodo.org/records/13382927
10.5281/zenodo.2672882,Picker-routing problem instances,2019-05-07,"The following instances are originally presented in the working paper &quot;High-density storage with mobile racks: Picker routing and product location&quot; written by Foroughi, Amir,&nbsp; Boysen, Nils, Emde, Simon, and&nbsp;Schneider, Michael.  The data corresponds to 360 instances each in its own file. Each file is structured as follows:  <ol> 	<li>The first line contains:&nbsp;the number of racks, the number of locations in each rack. (Please note that the number of aisles in each instance is the number of racks minus one)</li> 	<li>Then there follows a line with the name of each SKU.</li> 	<li>Then a line with waiting time in seconds (the time it takes for an aisle to be opened)</li> 	<li>Then a line with the distances from the aisle cross to the depot for each aisle.</li> 	<li>Then a line with the driving time between two consecutive aisles. It means how long it takes for the SRV to travel from one cross aisle to the next cross aisle.</li> 	<li>Then the lines for the location of SKUs in each rack, where each line is associated with one rack. In each pair of numbers, the first number is the name of SKU and the second number is the position of that SKU in the rack. For example, in the first rack, 3 1 5 3 2 4 means SKU 3 is in location 1, SKU 5 is in location 3, and SKU 2 is in location 4.</li> </ol>  All numbers in the same line are separated by spaces.","Foroughi, Amir, Boysen, Nils, Emde, Simon, Schneider, Michael",dataset,cc-by-4.0,https://zenodo.org/records/2672882
10.5281/zenodo.259352,Data for item-method directed forgetting and working memory capacity study,2017-01-24,"This dataset contains recall data from an item-method directed forgetting paradigm, working memory scores from the operation span (OSpan) and running span (RunSpan) tasks, and event frequencies for the multinomial storage-retrieval model (Riefer &amp; Rouder, 1992).  Detailed description of varibales in the dataset are contained in the pdf File ""VariableDescriptions_IMDF_WM_AllData.pdf"".","Ivan Marevic, Nina R. Arnold, Jan Rummel",dataset,cc-by-4.0,https://zenodo.org/records/259352
